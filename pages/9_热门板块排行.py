import streamlit as st
# å¯¼å…¥å…¨å±€åŠ©æ‰‹
try:
    from backend.helper import add_global_assistant
except ImportError:
    print("Error importing assistant helper")
import pandas as pd
import numpy as np
import plotly.express as px
import datetime
import traceback
import sys
import os
import sqlite3
import logging
from pathlib import Path
from collections import deque  # ç”¨äºæ”¶é›†è°ƒè¯•ä¿¡æ¯

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent
sys.path.insert(0, str(project_root))

# å…¨å±€å˜é‡ï¼Œç”¨äºæ”¶é›†è°ƒè¯•ä¿¡æ¯
if 'debug_messages' not in st.session_state:
    st.session_state.debug_messages = deque(maxlen=100)  # é™åˆ¶æœ€å¤§æ¶ˆæ¯æ•°é‡
    
# å®šä¹‰å‡½æ•°ç”¨äºæ”¶é›†è°ƒè¯•ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ç›´æ¥æ˜¾ç¤º
def add_debug_message(message, level="info"):
    """
    æ·»åŠ è°ƒè¯•ä¿¡æ¯åˆ°å…¨å±€é˜Ÿåˆ—ï¼Œè€Œä¸æ˜¯ç›´æ¥æ˜¾ç¤º
    
    Args:
        message: è°ƒè¯•ä¿¡æ¯å†…å®¹
        level: æ¶ˆæ¯çº§åˆ« (info, success, warning, error)
    """
    # å°†æ¶ˆæ¯æ·»åŠ åˆ°é˜Ÿåˆ—
    st.session_state.debug_messages.append((level, message))

# æ›¿æ¢åŸæ¥ç›´æ¥æ˜¾ç¤ºçš„è°ƒè¯•å‡½æ•°
def debug_info(message):
    """æ”¶é›†ä¿¡æ¯çº§åˆ«çš„è°ƒè¯•æ¶ˆæ¯"""
    add_debug_message(message, "info")
    
def debug_success(message):
    """æ”¶é›†æˆåŠŸçº§åˆ«çš„è°ƒè¯•æ¶ˆæ¯"""
    add_debug_message(message, "success")
    
def debug_warning(message):
    """æ”¶é›†è­¦å‘Šçº§åˆ«çš„è°ƒè¯•æ¶ˆæ¯"""
    add_debug_message(message, "warning")
    
def debug_error(message):
    """æ”¶é›†é”™è¯¯çº§åˆ«çš„è°ƒè¯•æ¶ˆæ¯"""
    add_debug_message(message, "error")

# åœ¨é¡µé¢åº•éƒ¨æ˜¾ç¤ºæ‰€æœ‰æ”¶é›†çš„è°ƒè¯•ä¿¡æ¯
def display_debug_messages():
    """åœ¨é¡µé¢åº•éƒ¨æ˜¾ç¤ºæ‰€æœ‰æ”¶é›†çš„è°ƒè¯•ä¿¡æ¯"""
    if st.session_state.debug_messages:
        with st.expander("è°ƒè¯•ä¿¡æ¯", expanded=False):
            for level, message in st.session_state.debug_messages:
                if level == "info":
                    st.info(message)
                elif level == "success":
                    st.success(message)
                elif level == "warning":
                    st.warning(message)
                elif level == "error":
                    st.error(message)

# é¡µé¢é…ç½®
st.set_page_config(page_title="çƒ­é—¨æ¿å—æ’è¡Œ", page_icon="ğŸ”¥", layout="wide")

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
def test_db_connection():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥å¹¶è¿”å›è¯Šæ–­ä¿¡æ¯"""
    results = {"success": False, "tables": [], "error": None, "db_path": None}
    
    try:
        # å…ˆå°è¯•ä»backend.dbå¯¼å…¥
        try:
            from backend.db import db
            results["success"] = True
            results["connection_type"] = "backend.dbæ¨¡å—"
            
            # å°è¯•è·å–æ‰€æœ‰è¡¨å
            try:
                query = "SELECT name FROM sqlite_master WHERE type='table';"
                tables_df = db.query_to_dataframe(query)
                if not tables_df.empty:
                    results["tables"] = tables_df['name'].tolist()
            except Exception as e:
                results["table_error"] = str(e)
                
        except ImportError as e:
            results["error"] = f"å¯¼å…¥backend.dbæ¨¡å—å¤±è´¥: {str(e)}"
            
            # å°è¯•ç›´æ¥è¿æ¥æ•°æ®åº“æ–‡ä»¶
            db_paths = [
                os.path.join(project_root, "plates.db"),
                os.path.join(project_root, "backend", "plates.db"),
                os.path.join(project_root, "data", "plates.db")
            ]
            
            for path in db_paths:
                if os.path.exists(path):
                    results["db_path"] = path
                    try:
                        conn = sqlite3.connect(path)
                        cursor = conn.cursor()
                        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
                        tables = cursor.fetchall()
                        results["tables"] = [table[0] for table in tables]
                        results["success"] = True
                        results["connection_type"] = f"ç›´æ¥è¿æ¥: {path}"
                        conn.close()
                        break
                    except Exception as e2:
                        results["error"] = f"ç›´æ¥è¿æ¥{path}å¤±è´¥: {str(e2)}"
            
    except Exception as e:
        results["error"] = f"æµ‹è¯•æ•°æ®åº“è¿æ¥æ—¶å‡ºé”™: {str(e)}"
    
    return results

# å¯¼å…¥æ•°æ®åº“æ¨¡å—
try:
    from backend.db import db
except ModuleNotFoundError:
    st.error("æ— æ³•å¯¼å…¥æ•°æ®åº“æ¨¡å—ï¼Œè¯·ç¡®ä¿ä»é¡¹ç›®æ ¹ç›®å½•å¯åŠ¨åº”ç”¨: streamlit run app.py")
    
    # å°è¯•è‡ªåŠ¨ä¿®å¤dbå¯¼å…¥
    try:
        # æ£€æŸ¥plates.dbæ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„dbæ¨¡å—
        db_paths = [
            os.path.join(project_root, "plates.db"),
            os.path.join(project_root, "backend", "plates.db"),
            os.path.join(project_root, "data", "plates.db")
        ]
        
        db_path = None
        for path in db_paths:
            if os.path.exists(path):
                db_path = path
                break
        
        if db_path:
            st.info(f"æ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶: {db_path}ï¼Œå°è¯•åˆ›å»ºä¸´æ—¶dbè¿æ¥...")
            
            # åˆ›å»ºä¸´æ—¶dbç±»
            class TempDB:
                def __init__(self, db_path):
                    self.db_path = db_path
                
                def query_to_dataframe(self, query, params=None):
                    try:
                        conn = sqlite3.connect(self.db_path)
                        if params:
                            df = pd.read_sql_query(query, conn, params=params)
                        else:
                            df = pd.read_sql_query(query, conn)
                        conn.close()
                        return df
                    except Exception as e:
                        st.error(f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥: {str(e)}")
                        st.code(query)
                        raise e
            
            db = TempDB(db_path)
            st.success("å·²åˆ›å»ºä¸´æ—¶æ•°æ®åº“è¿æ¥")
        else:
            st.error("æœªæ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶plates.db")
            if os.path.exists(os.path.join(project_root, "backend")):
                st.info(f"backendç›®å½•å­˜åœ¨ï¼Œå†…å®¹: {os.listdir(os.path.join(project_root, 'backend'))}")
            st.stop()
    except Exception as e:
        st.error(f"å°è¯•è‡ªåŠ¨ä¿®å¤dbå¯¼å…¥æ—¶å‡ºé”™: {str(e)}")
        st.stop()

# é¢œè‰²è®¾ç½®
POSITIVE_COLOR = "#f63366"  # çº¢è‰²ï¼Œç”¨äºæ­£å‘å˜åŒ–
NEGATIVE_COLOR = "#0068c9"  # è“è‰²ï¼Œç”¨äºè´Ÿå‘å˜åŒ–
HEADER_COLOR = "#F0F2F6"    # è¡¨å¤´èƒŒæ™¯è‰²
RANK_BG_COLORS = {
    1: "#FF4B4B",  # çº¢è‰²ï¼ˆæ’åç¬¬1ï¼‰
    2: "#FF8F65",  # æ©™è‰²ï¼ˆæ’åç¬¬2ï¼‰
    3: "#FFCA3A",  # é»„è‰²ï¼ˆæ’åç¬¬3ï¼‰
}

# é¡µé¢æ ‡é¢˜
st.title("çƒ­é—¨æ¿å—æ¯æ—¥æ’è¡Œ")

# è¾…åŠ©å‡½æ•°
def format_value(value, unit="äº¿"):
    """æ ¼å¼åŒ–æ•°å€¼ï¼Œæ·»åŠ å•ä½"""
    if pd.isna(value):
        return "-"
    if isinstance(value, (int, float)):
        if unit == "äº¿" and abs(value) >= 1:
            return f"{value:.1f}{unit}"  # å°æ•°ç‚¹ç²¾ç¡®åˆ°1ä½
        elif unit == "%" and not pd.isna(value):
            return f"{value:.1f}{unit}"  # å°æ•°ç‚¹ç²¾ç¡®åˆ°1ä½
        elif unit == "":
            return f"{value:.1f}"  # å°æ•°ç‚¹ç²¾ç¡®åˆ°1ä½
        else:
            return f"{value:.1f}{unit}"  # å°æ•°ç‚¹ç²¾ç¡®åˆ°1ä½
    return str(value)

@st.cache_data(ttl=300)
def get_recent_trading_dates(days=10):
    """è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥æœŸï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½"""
    try:
        # è®°å½•å½“å‰æ—¥æœŸï¼Œç”¨äºæ¯”è¾ƒ
        current_date = pd.Timestamp.now()
        
        # é¦–å…ˆè·å–å®é™…å­˜åœ¨æ•°æ®çš„äº¤æ˜“æ—¥æœŸï¼Œä½¿ç”¨JOINå­æŸ¥è¯¢ç»“æ„ï¼ˆå‚è€ƒ6_æ•°æ®å¯è§†åŒ–.pyï¼‰
        try:
            # ä»èµ„é‡‘æµè¡¨è·å–æœ€è¿‘çš„æœ‰æ•°æ®çš„äº¤æ˜“æ—¥æœŸ
            # æ³¨æ„ï¼šä¿®å¤MySQLä¸­LIKEè¯­å¥æ ¼å¼åŒ–é—®é¢˜ - ä½¿ç”¨åŒ%è½¬ä¹‰
            trade_date_query = f"""
                SELECT DISTINCT æ•°æ®æ—¥æœŸ 
                FROM capital_flow 
                WHERE ä»£ç  LIKE 'BK%%' 
                ORDER BY æ•°æ®æ—¥æœŸ DESC 
                LIMIT 60
            """
            
            # ç¡®ä¿æ²¡æœ‰æ¢è¡Œç¬¦å’Œå¤šä½™çš„ç©ºæ ¼
            trade_date_query = trade_date_query.replace("\n", " ").strip()
            
            trade_dates_df = db.query_to_dataframe(trade_date_query)
            
            if not trade_dates_df.empty:
                # å°†æ—¥æœŸè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼å¹¶éªŒè¯
                valid_dates = []
                skipped_dates = []
                
                for date in trade_dates_df['æ•°æ®æ—¥æœŸ']:
                    try:
                        # å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºå­—ç¬¦ä¸²
                        if isinstance(date, str):
                            date_obj = pd.to_datetime(date)
                        elif isinstance(date, pd.Timestamp) or isinstance(date, datetime.date):
                            date_obj = pd.to_datetime(date)
                        else:
                            skipped_dates.append((str(date), f"éæ—¥æœŸç±»å‹æ•°æ®: {type(date)}"))
                            continue
                        
                        # æ’é™¤æœªæ¥æ—¥æœŸï¼ˆè¶…è¿‡å½“å‰æ—¥æœŸ30å¤©ï¼‰
                        if date_obj > current_date + pd.Timedelta(days=30):
                            skipped_dates.append((date_obj.strftime('%Y-%m-%d'), f"è¿œæœŸæœªæ¥æ—¥æœŸ"))
                            continue
                        
                        # æ ¼å¼åŒ–ä¸ºæ ‡å‡†æ—¥æœŸå­—ç¬¦ä¸²
                        valid_dates.append(date_obj.strftime('%Y-%m-%d'))
                    except Exception as e:
                        skipped_dates.append((str(date), f"æ—¥æœŸæ ¼å¼æ— æ•ˆ: {str(e)}"))
                
                # ä»…è¿”å›è¯·æ±‚çš„å¤©æ•°
                if valid_dates:
                    return valid_dates[:days]
            
            # å¦‚æœèµ„é‡‘æµè¡¨æ²¡æœ‰æ•°æ®ï¼Œå°è¯•ä»sector_trendè¡¨è·å–æ—¥æœŸ
            sector_date_query = f"""
                SELECT DISTINCT æ•°æ®æ—¥æœŸ 
                FROM sector_trend 
                ORDER BY æ•°æ®æ—¥æœŸ DESC 
                LIMIT 60
            """
            
            sector_date_query = sector_date_query.replace("\n", " ").strip()
            sector_dates_df = db.query_to_dataframe(sector_date_query)
            
            if not sector_dates_df.empty:
                # éªŒè¯æ—¥æœŸ
                valid_dates = []
                
                for date in sector_dates_df['æ•°æ®æ—¥æœŸ']:
                    try:
                        if isinstance(date, str):
                            date_obj = pd.to_datetime(date)
                        elif isinstance(date, pd.Timestamp) or isinstance(date, datetime.date):
                            date_obj = pd.to_datetime(date)
                        else:
                            continue
                        
                        # æ’é™¤æœªæ¥æ—¥æœŸ
                        if date_obj > current_date + pd.Timedelta(days=30):
                            continue
                        
                        # æ ¼å¼åŒ–ä¸ºæ ‡å‡†æ—¥æœŸå­—ç¬¦ä¸²
                        valid_dates.append(date_obj.strftime('%Y-%m-%d'))
                    except Exception:
                        continue
                
                # ä»…è¿”å›è¯·æ±‚çš„å¤©æ•°
                if valid_dates:
                    return valid_dates[:days]
                    
        except Exception as e:
            # è®°å½•é”™è¯¯ä½†ç»§ç»­æ‰§è¡Œ
            st.error(f"è·å–æ—¥æœŸæ—¶å‡ºé”™: {str(e)}")
            st.code(traceback.format_exc())
        
        # å¦‚æœå®é™…äº¤æ˜“æ—¥æœŸè·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ—¥æœŸï¼ˆä»…å‘¨ä¸€è‡³å‘¨äº”ï¼‰
        simulated_dates = []
        current_date = pd.Timestamp.now()
        date_count = 0
        days_back = 0
        
        # ç”Ÿæˆè¶³å¤Ÿå¤šçš„å·¥ä½œæ—¥æ—¥æœŸï¼ˆæ’é™¤å‘¨æœ«ï¼‰
        while date_count < days:
            test_date = current_date - pd.Timedelta(days=days_back)
            days_back += 1
            
            # è·³è¿‡å‘¨å…­(5)å’Œå‘¨æ—¥(6)
            if test_date.weekday() < 5:  # 0-4 æ˜¯å‘¨ä¸€è‡³å‘¨äº”
                simulated_dates.append(test_date.strftime('%Y-%m-%d'))
                date_count += 1
        
        return simulated_dates
        
    except Exception as e:
        # ä»»ä½•æƒ…å†µä¸‹éƒ½è¿”å›æ¨¡æ‹Ÿæ—¥æœŸï¼Œç¡®ä¿å‡½æ•°ä¸ä¼šå¤±è´¥
        st.error(f"ç”Ÿæˆæ—¥æœŸæ—¶å‡ºé”™: {str(e)}")
        st.code(traceback.format_exc())
        
        simulated_dates = []
        current_date = pd.Timestamp.now()
        date_count = 0
        days_back = 0
        
        while date_count < days:
            test_date = current_date - pd.Timedelta(days=days_back)
            days_back += 1
            
            # è·³è¿‡å‘¨æœ«
            if test_date.weekday() < 5:  # 0-4 æ˜¯å‘¨ä¸€è‡³å‘¨äº”
                simulated_dates.append(test_date.strftime('%Y-%m-%d'))
                date_count += 1
        
        return simulated_dates

def get_all_indicators():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æŒ‡æ ‡"""
    # åŒ…å«æ‰€æœ‰å››ä¸ªè¡¨çš„æŒ‡æ ‡
    indicators = {
        # èµ„é‡‘æµç›¸å…³æŒ‡æ ‡ (æ¥è‡ªcapital_flowè¡¨)
        "ä¸»åŠ›å‡€æµå…¥": {"table": "capital_flow", "field": "ä¸»åŠ›å‡€æµå…¥", "unit": "äº¿"},
        "è¶…å¤§å•å‡€é¢": {"table": "capital_flow", "field": "è¶…å¤§å•å‡€é¢", "unit": "äº¿"},
        "å¤§å•å‡€é¢": {"table": "capital_flow", "field": "å¤§å•å‡€é¢", "unit": "äº¿"},
        "ä¸­å•å‡€é¢": {"table": "capital_flow", "field": "ä¸­å•å‡€é¢", "unit": "äº¿"},
        "å°å•å‡€é¢": {"table": "capital_flow", "field": "å°å•å‡€é¢", "unit": "äº¿"},
        
        # DDEè¡Œä¸ºæŒ‡æ ‡ (æ¥è‡ªdde_analysisè¡¨)
        "DDX": {"table": "dde_analysis", "field": "DDX", "unit": ""},
        "DDY": {"table": "dde_analysis", "field": "DDY", "unit": ""},
        "DDZ": {"table": "dde_analysis", "field": "DDZ", "unit": ""},
        "5æ—¥DDX": {"table": "dde_analysis", "field": "5æ—¥DDX", "unit": ""},
        "5æ—¥DDY": {"table": "dde_analysis", "field": "5æ—¥DDY", "unit": ""},
        "ç‰¹å¤§å•å‡€æ¯”": {"table": "dde_analysis", "field": "ç‰¹å¤§å•å‡€æ¯”%", "unit": "%"},
        
        # å¢ä»“ç»“æ„æŒ‡æ ‡ (æ¥è‡ªposition_analysisè¡¨)
        "ä»Šæ—¥å¢ä»“å æ¯”": {"table": "position_analysis", "field": "ä»Šæ—¥å¢ä»“å æ¯”", "unit": "%"},
        "3æ—¥å¢ä»“å æ¯”": {"table": "position_analysis", "field": "3æ—¥å¢ä»“å æ¯”", "unit": "%"},
        "5æ—¥å¢ä»“å æ¯”": {"table": "position_analysis", "field": "5æ—¥å¢ä»“å æ¯”", "unit": "%"},
        "ä»Šæ—¥æ’å": {"table": "position_analysis", "field": "ä»Šæ—¥æ’å", "unit": ""},
        
        # æ¿å—è¶‹åŠ¿æŒ‡æ ‡ (æ¥è‡ªsector_trendè¡¨)
        "æ¶¨å¹…": {"table": "sector_trend", "field": "æ¶¨å¹…%", "unit": "%"},
        "æ¶¨é€Ÿ": {"table": "sector_trend", "field": "æ¶¨é€Ÿ%", "unit": "%"},
        "æ¢æ‰‹ç‡": {"table": "sector_trend", "field": "æ¢æ‰‹%", "unit": "%"},
        "æˆäº¤é‡‘é¢": {"table": "sector_trend", "field": "é‡‘é¢", "unit": "äº¿"},
        "æ€»å¸‚å€¼": {"table": "sector_trend", "field": "æ€»å¸‚å€¼", "unit": "äº¿"},
        "æµé€šå¸‚å€¼": {"table": "sector_trend", "field": "æµé€šå¸‚å€¼", "unit": "äº¿"},
        "æ¶¨è·Œæ¯”": {"table": "sector_trend", "field": "æ¶¨è·Œæ¯”", "unit": ""},
        "æ¶¨å®¶æ•°": {"table": "sector_trend", "field": "æ¶¨å®¶æ•°", "unit": "å®¶"},
        "è·Œå®¶æ•°": {"table": "sector_trend", "field": "è·Œå®¶æ•°", "unit": "å®¶"},
        "æ¶¨åœå®¶æ•°": {"table": "sector_trend", "field": "æ¶¨åœå®¶æ•°", "unit": "å®¶"},
        "3æ—¥æ¶¨å¹…": {"table": "sector_trend", "field": "3æ—¥æ¶¨å¹…%", "unit": "%"},
        "3æ—¥æ¢æ‰‹ç‡": {"table": "sector_trend", "field": "3æ—¥æ¢æ‰‹%", "unit": "%"},
    }
    return indicators

@st.cache_data(ttl=60)
def get_hot_sectors(indicator_info, dates, rank_limit=100, get_bottom=False, board_type=None):
    """
    è·å–çƒ­é—¨æ¿å—æ’è¡Œæ•°æ®ï¼Œä½¿ç”¨ç¼“å­˜æé«˜æ€§èƒ½
    å‚è€ƒ6_æ•°æ®å¯è§†åŒ–.pyä¸­çš„æ–¹å¼ï¼Œé¿å…SQLæ³¨å…¥å’ŒåŠ¨æ€æ„å»ºé£é™©
    
    Args:
        indicator_info: æ’åºæŒ‡æ ‡ä¿¡æ¯ï¼ˆåŒ…å«è¡¨åã€å­—æ®µåå’Œå•ä½ï¼‰
        dates: æ—¥æœŸåˆ—è¡¨
        rank_limit: è¿”å›çš„æœ€å¤§æ’åæ•°
        get_bottom: æ˜¯å¦è·å–è´Ÿå€¼æœ€å¤§çš„æ¿å—ï¼ˆåº•éƒ¨æ’åï¼‰
        board_type: æ¿å—ç±»å‹è¿‡æ»¤ï¼ˆæ¦‚å¿µã€è¡Œä¸šã€åœ°åŒºã€é£æ ¼ï¼‰
        
    Returns:
        åŒ…å«å¤šä¸ªæ—¥æœŸæ’åæ•°æ®çš„DataFrame
    """
    if not dates:
        debug_warning("æ— æœ‰æ•ˆæ—¥æœŸæ•°æ®")
        return pd.DataFrame()
    
    try:
        # è§£ææŒ‡æ ‡ä¿¡æ¯
        table = indicator_info["table"]
        field = indicator_info["field"]
        
        debug_info(f"è·å–è¡¨ {table} çš„å­—æ®µ {field} æ•°æ®")
        
        # é¦–å…ˆè¿‡æ»¤æ‰æœªæ¥æ—¥æœŸ
        current_date = pd.Timestamp.now()
        filtered_dates = []
        for date in dates:
            try:
                parsed_date = pd.to_datetime(date)
                # å¦‚æœæ—¥æœŸæ˜¯æœªæ¥çš„ï¼Œè·³è¿‡
                if parsed_date > current_date + pd.Timedelta(days=1):  # å…è®¸ä»Šå¤©å’Œæ˜å¤©çš„æ—¥æœŸ
                    debug_warning(f"æ—¥æœŸ {date} æ˜¯æœªæ¥æ—¥æœŸï¼Œå·²è·³è¿‡")
                    continue
                filtered_dates.append(date)
            except:
                # å¦‚æœæ—¥æœŸæ— æ³•è§£æï¼Œä¹Ÿè·³è¿‡
                debug_warning(f"æ—¥æœŸ {date} æ— æ³•è§£æï¼Œå·²è·³è¿‡")
                continue
        
        if not filtered_dates:
            debug_warning("æ‰€æœ‰æ—¥æœŸå‡æ— æ•ˆæˆ–æ˜¯æœªæ¥æ—¥æœŸ")
            return pd.DataFrame()
        
        # å¦‚æœéœ€è¦æŒ‰æ¿å—ç±»å‹è¿‡æ»¤ï¼Œå…ˆè·å–ç›¸åº”çš„board_nameæˆ–åç§°åˆ—è¡¨
        valid_board_names = []
        valid_board_codes = []
        if board_type:
            debug_info(f"å‡†å¤‡æ ¹æ®æ¿å—ç±»å‹ '{board_type}' è¿‡æ»¤æ•°æ®...")
            try:
                # ä»bk_type_mappingè·å–æ‰€éœ€æ¿å—ç±»å‹çš„æ¿å—åç§°å’Œä»£ç 
                type_query = f"""
                SELECT bk_code, board_name 
                FROM bk_type_mapping 
                WHERE board_type = '{board_type}'
                """
                mapping_df = db.query_to_dataframe(type_query)
                
                if not mapping_df.empty:
                    # æå–æ¿å—ä»£ç ï¼ˆç”¨äºcapital_flow, dde_analysis, position_analysisè¡¨ï¼‰
                    if 'bk_code' in mapping_df.columns:
                        board_codes = mapping_df['bk_code'].dropna().tolist()
                        if board_codes:
                            valid_board_codes = board_codes
                            add_debug_message(f"æ‰¾åˆ° {len(valid_board_codes)} ä¸ªç±»å‹ä¸º '{board_type}' çš„æ¿å—ä»£ç ", "info")
                            add_debug_message(f"æ¿å—ä»£ç åˆ—è¡¨: {', '.join(board_codes[:10])}{'...' if len(board_codes) > 10 else ''}", "info")
                    
                    # æå–æ¿å—åç§°ï¼ˆç”¨äºsector_trendè¡¨ï¼‰
                    if 'board_name' in mapping_df.columns:
                        board_names = mapping_df['board_name'].dropna().tolist()
                        if board_names:
                            valid_board_names = board_names
                            add_debug_message(f"æ‰¾åˆ° {len(valid_board_names)} ä¸ªç±»å‹ä¸º '{board_type}' çš„æ¿å—åç§°", "info")
                            add_debug_message(f"æ¿å—åç§°åˆ—è¡¨: {', '.join(board_names[:10])}{'...' if len(board_names) > 10 else ''}", "info")
                    
                    # è¿˜éœ€è¦ä»capital_flowè¡¨è·å–æ¿å—åç§°ï¼ˆè¿™äº›å¯èƒ½æ˜¯sector_trendè¡¨ä¸­ä½¿ç”¨çš„åç§°ï¼‰
                    if valid_board_codes:
                        bk_codes_str = "', '".join(valid_board_codes)
                        
                        # ä»capital_flowè¡¨è·å–è¿™äº›ä»£ç å¯¹åº”çš„åç§°
                        names_query = f"""
                        SELECT DISTINCT ä»£ç , åç§° 
                        FROM capital_flow 
                        WHERE ä»£ç  IN ('{bk_codes_str}')
                        """
                        names_df = db.query_to_dataframe(names_query)
                        
                        if not names_df.empty:
                            add_debug_message(f"ä»capital_flowè¡¨è·å–åˆ° {len(names_df)} æ¡ä»£ç -åç§°è®°å½•", "info")
                            add_debug_message(f"ä»£ç -åç§°æ˜ å°„æ ·æœ¬: {names_df.head(5).to_string()}", "info")
                            more_names = names_df['åç§°'].dropna().tolist()
                            
                            # åˆ›å»ºä»£ç åˆ°åç§°çš„æ˜ å°„å¹¶æ‰“å°
                            code_to_name = dict(zip(names_df['ä»£ç '], names_df['åç§°']))
                            add_debug_message(f"éƒ¨åˆ†ä»£ç åˆ°åç§°æ˜ å°„: {dict(list(code_to_name.items())[:5])}", "info")
                            
                            valid_board_names.extend(more_names)
                            debug_info(f"ä»capital_flowè¡¨è·å–åˆ°é¢å¤–çš„ {len(more_names)} ä¸ªæ¿å—åç§°")
                            if more_names:
                                add_debug_message(f"é¢å¤–çš„æ¿å—åç§°: {', '.join(more_names[:10])}{'...' if len(more_names) > 10 else ''}", "info")
                        else:
                            add_debug_message(f"åœ¨capital_flowè¡¨ä¸­æœªæ‰¾åˆ°åŒ¹é…çš„ä»£ç -åç§°è®°å½•", "warning")
                            add_debug_message(f"æŸ¥è¯¢: {names_query}", "info")
                else:
                    debug_warning(f"æ‰¾ä¸åˆ°ç±»å‹ä¸º '{board_type}' çš„æ¿å—")
                    add_debug_message(f"æŸ¥è¯¢: {type_query}", "info")
                    add_debug_message(f"è¯·æ£€æŸ¥bk_type_mappingè¡¨ä¸­æ˜¯å¦æœ‰'{board_type}'ç±»å‹çš„è®°å½•", "warning")
            except Exception as e:
                debug_error(f"è·å–æ¿å—ç±»å‹æ˜ å°„æ—¶å‡ºé”™: {str(e)}")
                add_debug_message(f"æŸ¥è¯¢: {type_query if 'type_query' in locals() else 'æœªæ‰§è¡ŒæŸ¥è¯¢'}", "info")
                if traceback:
                    debug_error(traceback.format_exc())
                    
        # æ‰“å°ç­›é€‰åçš„æœ‰æ•ˆæ¿å—åç§°å’Œä»£ç æ•°é‡
        add_debug_message(f"æœ€ç»ˆè·å–åˆ° {len(valid_board_names)} ä¸ªæ¿å—åç§°å’Œ {len(valid_board_codes)} ä¸ªæ¿å—ä»£ç ", "info")
        if valid_board_names:
            add_debug_message(f"åç§°ç¤ºä¾‹: {', '.join(valid_board_names[:10])}{'...' if len(valid_board_names) > 10 else ''}", "info")
        if valid_board_codes:
            add_debug_message(f"ä»£ç ç¤ºä¾‹: {', '.join(valid_board_codes[:10])}{'...' if len(valid_board_codes) > 10 else ''}", "info")
        
        # åˆ›å»ºæ—¥æœŸåˆ—è¡¨å­—ç¬¦ä¸²ï¼Œç”¨äºINå­å¥
        date_str_list = "', '".join(filtered_dates)
        date_filter = f"DATE(æ•°æ®æ—¥æœŸ) IN ('{date_str_list}')"
        
        # 1. é¦–å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        try:
            test_query = f"SELECT 1 FROM {table} LIMIT 1"
            test_df = db.query_to_dataframe(test_query)
            debug_success(f"è¡¨ {table} å­˜åœ¨å¹¶å¯ä»¥è®¿é—®")
        except Exception as e:
            debug_error(f"è¡¨ {table} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {str(e)}")
            if traceback:
                debug_error(traceback.format_exc())
            return pd.DataFrame()
        
        # 2. æ„å»ºæŸ¥è¯¢ - æ ¹æ®æ˜¯å¦è·å–åº•éƒ¨æ’åä½¿ç”¨ä¸åŒçš„SQLè¯­å¥
        try:
            # æ„å»ºæŸ¥è¯¢ï¼Œä¸åŒè¡¨ä½¿ç”¨ä¸åŒçš„æŸ¥è¯¢æ¨¡å¼
            if table == "capital_flow":
                if board_type and valid_board_codes:
                    # ä½¿ç”¨æ¿å—ä»£ç åˆ—è¡¨è¿‡æ»¤
                    board_codes_str = "', '".join(valid_board_codes)
                    add_debug_message(f"ä½¿ç”¨ {len(valid_board_codes)} ä¸ªæ¿å—ä»£ç è¿‡æ»¤ capital_flow è¡¨", "info")
                    
                    if get_bottom and ("æµå…¥" in field or "é‡‘é¢" in field or "å‡€é¢" in field):
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND ä»£ç  IN ('{board_codes_str}') 
                            ORDER BY æ•°æ®æ—¥æœŸ DESC, {field} ASC
                        """
                        debug_info("æ­£åœ¨æŸ¥è¯¢èµ„é‡‘æµå‡ºæœ€å¤§çš„æ¿å—ï¼ˆè´Ÿå€¼æœ€å¤§ï¼‰")
                    else:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND ä»£ç  IN ('{board_codes_str}') 
                            ORDER BY æ•°æ®æ—¥æœŸ DESC
                        """
                elif not board_type:
                    # ä¸éœ€è¦è¿‡æ»¤ï¼Œä½¿ç”¨LIKE BK% åŒ¹é…æ‰€æœ‰æ¿å—
                    if get_bottom and ("æµå…¥" in field or "é‡‘é¢" in field or "å‡€é¢" in field):
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND ä»£ç  LIKE 'BK%%' 
                            ORDER BY æ•°æ®æ—¥æœŸ DESC, {field} ASC
                        """
                        debug_info("æ­£åœ¨æŸ¥è¯¢èµ„é‡‘æµå‡ºæœ€å¤§çš„æ¿å—ï¼ˆè´Ÿå€¼æœ€å¤§ï¼‰")
                    else:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND ä»£ç  LIKE 'BK%%' 
                            ORDER BY æ•°æ®æ—¥æœŸ DESC
                        """
                else:
                    debug_warning(f"æ²¡æœ‰æ‰¾åˆ°ç±»å‹ä¸º '{board_type}' çš„æ¿å—ä»£ç ")
                    return pd.DataFrame()
            elif table == "sector_trend":
                # å¯¹äºsector_trendè¡¨ï¼Œä½¿ç”¨åç§°åŒ¹é…æ¿å—ç±»å‹
                if board_type and valid_board_names:
                    # æ„å»ºåç§°INå­å¥
                    names_str = "', '".join(valid_board_names)
                    
                    # è®°å½•å®é™…ä½¿ç”¨çš„åç§°åˆ—è¡¨
                    add_debug_message(f"ä½¿ç”¨ {len(valid_board_names)} ä¸ªæ¿å—åç§°è¿‡æ»¤ sector_trend è¡¨", "info")
                    
                    if get_bottom:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND åç§° IN ('{names_str}')
                            ORDER BY æ•°æ®æ—¥æœŸ DESC, {field} ASC
                        """
                    else:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND åç§° IN ('{names_str}')
                            ORDER BY æ•°æ®æ—¥æœŸ DESC
                        """
                    debug_info(f"ä½¿ç”¨æ¿å—åç§°åˆ—è¡¨è¿‡æ»¤sector_trendè¡¨æ•°æ®")
                elif not board_type:
                    # ä¸éœ€è¦è¿‡æ»¤æˆ–æ²¡æœ‰æœ‰æ•ˆçš„æ¿å—åç§°åˆ—è¡¨
                    if get_bottom:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter}
                            ORDER BY æ•°æ®æ—¥æœŸ DESC, {field} ASC
                        """
                    else:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter}
                            ORDER BY æ•°æ®æ—¥æœŸ DESC
                        """
                else:
                    debug_warning(f"æ²¡æœ‰æ‰¾åˆ°ç±»å‹ä¸º '{board_type}' çš„æ¿å—åç§°")
                    return pd.DataFrame()
            elif table == "dde_analysis" or table == "position_analysis":
                # å¯¹äºdde_analysiså’Œposition_analysisè¡¨ï¼Œä¹Ÿé€šè¿‡ä»£ç åŒ¹é…æ¿å—ç±»å‹
                if board_type and valid_board_codes:
                    # æ„å»ºä»£ç INå­å¥
                    board_codes_str = "', '".join(valid_board_codes)
                    
                    add_debug_message(f"ä½¿ç”¨ {len(valid_board_codes)} ä¸ªæ¿å—ä»£ç è¿‡æ»¤ {table} è¡¨", "info")
                    
                    if get_bottom:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND ä»£ç  IN ('{board_codes_str}') 
                            ORDER BY æ•°æ®æ—¥æœŸ DESC, {field} ASC
                        """
                    else:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND ä»£ç  IN ('{board_codes_str}') 
                            ORDER BY æ•°æ®æ—¥æœŸ DESC
                        """
                    debug_info(f"ä½¿ç”¨æ¿å—ä»£ç åˆ—è¡¨è¿‡æ»¤{table}è¡¨æ•°æ®")
                elif not board_type:
                    # ä¸éœ€è¦è¿‡æ»¤ï¼Œä½¿ç”¨LIKE BK% åŒ¹é…æ‰€æœ‰æ¿å—
                    if get_bottom:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND ä»£ç  LIKE 'BK%%' 
                            ORDER BY æ•°æ®æ—¥æœŸ DESC, {field} ASC
                        """
                    else:
                        query = f"""
                            SELECT * FROM {table} 
                            WHERE {date_filter} AND ä»£ç  LIKE 'BK%%' 
                            ORDER BY æ•°æ®æ—¥æœŸ DESC
                        """
                else:
                    debug_warning(f"æ²¡æœ‰æ‰¾åˆ°ç±»å‹ä¸º '{board_type}' çš„æ¿å—ä»£ç ")
                    return pd.DataFrame()
            else:
                debug_error(f"ä¸æ”¯æŒçš„è¡¨å: {table}")
                return pd.DataFrame()
            
            # ç¡®ä¿æ²¡æœ‰æ¢è¡Œç¬¦å’Œå¤šä½™çš„ç©ºæ ¼
            query = query.replace("\n", " ").strip()
            
            # æ˜¾ç¤ºSQLæŸ¥è¯¢å†…å®¹åˆ°è°ƒè¯•åŒº
            add_debug_message(f"SQLæŸ¥è¯¢:\n{query}", "info")
            
            # æ‰§è¡ŒæŸ¥è¯¢è·å–æ‰€æœ‰å­—æ®µ
            debug_info(f"æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢...")
            df = db.query_to_dataframe(query)
            
            if df.empty:
                debug_warning(f"æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œå¯èƒ½æŒ‡å®šçš„æ—¥æœŸåœ¨è¡¨ {table} ä¸­ä¸å­˜åœ¨æ•°æ®")
                return pd.DataFrame()
            
            debug_success(f"æŸ¥è¯¢æˆåŠŸï¼Œè·å–åˆ° {len(df)} æ¡è®°å½•")
            
            # ç¡®ä¿æ•°æ®æ—¥æœŸåˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            if 'æ•°æ®æ—¥æœŸ' in df.columns:
                df['æ•°æ®æ—¥æœŸ'] = df['æ•°æ®æ—¥æœŸ'].astype(str)
                debug_info(f"æ•°æ®æ—¥æœŸèŒƒå›´: {df['æ•°æ®æ—¥æœŸ'].min()} è‡³ {df['æ•°æ®æ—¥æœŸ'].max()}")
            
            # ç¡®ä¿ç›®æ ‡å­—æ®µå­˜åœ¨
            if field not in df.columns:
                debug_error(f"å­—æ®µ {field} åœ¨è¡¨ {table} ä¸­ä¸å­˜åœ¨")
                # æ˜¾ç¤ºè¡¨ä¸­å­˜åœ¨çš„åˆ—
                add_debug_message(f"è¡¨ä¸­å­˜åœ¨çš„åˆ—: {df.columns.tolist()}", "info")
                return pd.DataFrame()
            
            # æ·»åŠ indicator_valueåˆ—ï¼Œç”¨äºåç»­å¤„ç†
            df['indicator_value'] = df[field]
            
            # å¯¹æ¯ä¸ªæ—¥æœŸè®¡ç®—æ’å
            if get_bottom:
                # å¯¹äºåº•éƒ¨æ’åï¼Œä½¿ç”¨å‡åºæ’åï¼ˆå€¼è¶Šå°æ’åè¶Šé«˜ï¼‰
                df['rank'] = df.groupby('æ•°æ®æ—¥æœŸ')[field].rank(ascending=True, method='min')
            else:
                # å¯¹äºé¡¶éƒ¨æ’åï¼Œä½¿ç”¨é™åºæ’åï¼ˆå€¼è¶Šå¤§æ’åè¶Šé«˜ï¼‰
                df['rank'] = df.groupby('æ•°æ®æ—¥æœŸ')[field].rank(ascending=False, method='min')
            
            # åªä¿ç•™æ¯ä¸ªæ—¥æœŸçš„å‰Nå
            df = df[df['rank'] <= rank_limit]
            
            return df
            
        except Exception as e:
            debug_error(f"æŸ¥è¯¢æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            if traceback:
                debug_error(traceback.format_exc())
            return pd.DataFrame()
    
    except Exception as e:
        debug_error(f"è·å–çƒ­é—¨æ¿å—æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        if traceback:
            debug_error(traceback.format_exc())
        # ä»»ä½•æ„å¤–é”™è¯¯ï¼Œè¿”å›ç©ºDataFrame
        return pd.DataFrame()

def create_mock_sector_data(indicator_info, dates, rank_limit=100, board_type=None):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„æ¿å—æ•°æ®ï¼Œç”¨äºåœ¨æ•°æ®åº“æŸ¥è¯¢å¤±è´¥æ—¶å±•ç¤º"""
    # æ­¤å‡½æ•°å·²ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å‡½æ•°å®šä¹‰ä»¥ä¿è¯ä»£ç ç»“æ„å®Œæ•´æ€§
    # è¿”å›ç©ºDataFrame
    return pd.DataFrame()

def generate_rank_table(data, dates, indicator, rank_limit=100, show_limit=10, unit=""):
    """
    ç”Ÿæˆæ’åè¡¨æ ¼
    
    Args:
        data: åŒ…å«æ’åæ•°æ®çš„DataFrame
        dates: æ—¥æœŸåˆ—è¡¨
        indicator: æ’åºæŒ‡æ ‡
        rank_limit: æœ€å¤§æ’åæ•°
        show_limit: æ˜¾ç¤ºçš„æ’åæ•°
        unit: æŒ‡æ ‡å•ä½
        
    Returns:
        HTMLæ ¼å¼çš„è¡¨æ ¼
    """
    if data.empty:
        return "<p>æ— æ•°æ®</p>"
    
    # æ•°æ®é¢„å¤„ç† - ç¡®ä¿æ•°æ®æ—¥æœŸæ ¼å¼ä¸€è‡´
    if 'æ•°æ®æ—¥æœŸ' in data.columns:
        data['æ•°æ®æ—¥æœŸ_str'] = data['æ•°æ®æ—¥æœŸ'].astype(str)
        
        # å¤„ç†æ¯ä¸ªæ—¥æœŸçš„æ•°æ®åŒ¹é…
        for date in dates:
            try:
                # å°è¯•ä¸åŒçš„åŒ¹é…æ–¹å¼
                # 1. ç²¾ç¡®åŒ¹é…
                exact_match = data[data['æ•°æ®æ—¥æœŸ_str'] == date]
                # 2. æ—¥æœŸéƒ¨åˆ†åŒ¹é… (åªæ¯”è¾ƒå¹´æœˆæ—¥)
                date_part_match = data[data['æ•°æ®æ—¥æœŸ_str'].str.startswith(date.split()[0] if ' ' in date else date)]
                
                # ä½¿ç”¨æ•ˆæœæœ€å¥½çš„åŒ¹é…æ–¹å¼
                if len(exact_match) > 0:
                    data.loc[exact_match.index, 'æ—¥æœŸåŒ¹é…'] = date
                elif len(date_part_match) > 0:
                    data.loc[date_part_match.index, 'æ—¥æœŸåŒ¹é…'] = date
            except Exception:
                pass
    else:
        # æ·»åŠ ä¸€ä¸ªè™šæ‹Ÿæ—¥æœŸåˆ—ä»¥ç»§ç»­
        data['æ—¥æœŸåŒ¹é…'] = dates[0] if dates else ""
    
    # å‡†å¤‡è¡¨æ ¼å¤´éƒ¨ - æ—¥æœŸæ ¼å¼ä¸ºMM-DD
    date_headers = [pd.to_datetime(date).strftime('%m-%d') for date in dates]
    
    # æ„å»ºHTMLè¡¨æ ¼
    html = """
    <style>
    .hot-sectors-table {
        width: 100%;
        border-collapse: collapse;
        font-family: Arial, sans-serif;
        text-align: center;
        border: 1px solid #e6e6e6;
    }
    .hot-sectors-table th {
        background-color: #F7F7F7;
        padding: 10px;
        border: 1px solid #e6e6e6;
        font-weight: normal;
        position: sticky;
        top: 0;
    }
    .hot-sectors-table td {
        padding: 0;
        border: 1px solid #e6e6e6;
        vertical-align: middle;
        height: 80px;
    }
    .hot-sectors-table tr:nth-child(even) {
        background-color: #FFFFFF;
    }
    .hot-sectors-table tr:nth-child(odd) {
        background-color: #FFFFFF;
    }
    .rank-cell {
        width: 50px;
        height: 50px;
        line-height: 50px;
        font-weight: bold;
        color: white;
        font-size: 22px;
        text-align: center;
        vertical-align: middle;
    }
    .rank-1 { background-color: #FF3A3A; }
    .rank-2 { background-color: #FF8843; }
    .rank-3 { background-color: #FFBA37; }
    .rank-other { background-color: #808080; }
    .sector-name {
        font-weight: normal;
        text-align: center;
        font-size: 15px;
        padding: 10px 5px 5px 5px;
    }
    .indicator-value {
        font-weight: bold;
        color: #FF3A3A;
        text-align: center;
        font-size: 17px;
        padding: 5px 5px 10px 5px;
    }
    .cell-with-border {
        border: 1px solid #e0c8c8;
        padding: 0;
        height: 100%;
    }
    </style>
    <table class='hot-sectors-table'>
        <tr>
            <th>æ’å</th>
    """
    
    # æ·»åŠ æ—¥æœŸåˆ—
    for date in date_headers:
        html += f"<th>{date}</th>"
    
    html += "</tr>"
    
    # æ£€æŸ¥å¿…è¦å­—æ®µ
    required_fields = ['åç§°', 'indicator_value', 'rank']
    missing_fields = [field for field in required_fields if field not in data.columns]
    
    if missing_fields:
        # å¦‚æœç¼ºå°‘å­—æ®µï¼Œæ·»åŠ é»˜è®¤å€¼
        for field in missing_fields:
            if field == 'åç§°':
                data['åç§°'] = "æœªçŸ¥æ¿å—"
            elif field == 'indicator_value':
                data['indicator_value'] = 0
            elif field == 'rank':
                data['rank'] = range(1, len(data) + 1)
    
    # è·å–å‰Nåæ•°æ® - æ”¹ç”¨æ—¥æœŸåŒ¹é…åˆ—
    pivoted_data = {}
    
    # å¯¹äºæ¯ä¸ªæ—¥æœŸ
    for date in dates:
        # ä½¿ç”¨æ—¥æœŸåŒ¹é…åˆ—ç­›é€‰
        date_df = data[data.get('æ—¥æœŸåŒ¹é…', '') == date].copy() if 'æ—¥æœŸåŒ¹é…' in data.columns else data[data['æ•°æ®æ—¥æœŸ_str'] == date].copy()
        
        if not date_df.empty:
            date_df = date_df.sort_values(by='rank')
            
            # åªå–å‰show_limitå
            date_df = date_df.head(show_limit)
            
            # å­˜å‚¨æ¯ä¸ªæ—¥æœŸçš„æ’åæ•°æ®
            for _, row in date_df.iterrows():
                try:
                    rank = int(row['rank'])
                    if rank not in pivoted_data:
                        pivoted_data[rank] = {}
                    
                    pivoted_data[rank][date] = {
                        'name': row['åç§°'],
                        'value': row['indicator_value']
                    }
                except:
                    continue
    
    # ç”Ÿæˆè¡¨æ ¼è¡Œ
    for rank in range(1, show_limit + 1):
        html += "<tr>"
        
        # æ’åå•å…ƒæ ¼
        rank_class = f"rank-{rank}" if rank <= 3 else "rank-other"
        html += f"<td class='rank-cell {rank_class}'>{rank}</td>"
        
        # å¯¹äºæ¯ä¸ªæ—¥æœŸçš„æ•°æ®
        for date in dates:
            if rank in pivoted_data and date in pivoted_data[rank]:
                cell_data = pivoted_data[rank][date]
                name = cell_data['name']
                value = cell_data['value']
                
                formatted_value = format_value(value, unit)
                
                # å¯¹äºå‰3åä½¿ç”¨è¾¹æ¡†é«˜äº®
                if rank <= 3:
                    # ç¬¬ä¸€åæœ‰ç‰¹æ®Šè¾¹æ¡†
                    if rank == 1:
                        td_style = "style='padding:0;'"
                        inner_style = "style='border:2px solid #e0c8c8;padding:0;'"
                    else:
                        td_style = "style='padding:0;'"
                        inner_style = ""
                    
                    html += f"""
                    <td {td_style}>
                        <div {inner_style}>
                            <div class='sector-name'>{name}</div>
                            <div class='indicator-value'>{formatted_value}</div>
                        </div>
                    </td>
                    """
                else:
                    html += f"""
                    <td>
                        <div class='sector-name'>{name}</div>
                        <div class='indicator-value'>{formatted_value}</div>
                    </td>
                    """
            else:
                html += "<td>-</td>"
        
        html += "</tr>"
    
    html += "</table>"
    return html

def get_rank_change_data(data, dates, indicator):
    """è·å–æ¿å—æ’åå˜åŒ–æ•°æ®"""
    if len(dates) < 2 or data.empty:
        return pd.DataFrame()
    
    # å–æœ€æ–°ä¸¤ä¸ªæ—¥æœŸ
    latest_date = dates[0]
    prev_date = dates[1]
    
    # è·å–è¿™ä¸¤ä¸ªæ—¥æœŸçš„æ•°æ®
    latest_df = data[data['æ•°æ®æ—¥æœŸ'] == latest_date].copy()
    prev_df = data[data['æ•°æ®æ—¥æœŸ'] == prev_date].copy()
    
    # åˆå¹¶æ•°æ®ï¼Œè®¡ç®—æ’åå˜åŒ–
    merged = pd.merge(
        latest_df[['åç§°', 'rank', 'indicator_value']],
        prev_df[['åç§°', 'rank', 'indicator_value']],
        on='åç§°', how='inner', suffixes=('_latest', '_prev')
    )
    
    # è®¡ç®—æ’åå˜åŒ–å’ŒæŒ‡æ ‡å˜åŒ–
    merged['rank_change'] = merged['rank_prev'] - merged['rank_latest']  # æ­£å€¼è¡¨ç¤ºæ’åä¸Šå‡
    merged['value_change'] = merged['indicator_value_latest'] - merged['indicator_value_prev']
    
    # è¿”å›æ’åå˜åŒ–æœ€å¤§çš„Nä¸ªæ¿å—
    return merged.sort_values(by='rank_change', ascending=False)

def create_rank_change_chart(change_data, indicator):
    """åˆ›å»ºæ’åå˜åŒ–å›¾è¡¨"""
    if change_data.empty:
        return None
    
    # å–æ’åå˜åŒ–æœ€å¤§çš„5ä¸ªä¸Šå‡å’Œ5ä¸ªä¸‹é™
    top_rise = change_data[change_data['rank_change'] > 0].head(5)
    top_fall = change_data[change_data['rank_change'] < 0].tail(5).iloc[::-1]  # åè½¬ï¼Œä½¿é™å¹…æœ€å¤§çš„åœ¨åº•éƒ¨
    
    # åˆå¹¶æ•°æ®
    plot_data = pd.concat([top_rise, top_fall])
    
    if plot_data.empty:
        return None
    
    # åˆ›å»ºæ¨ªå‘æ¡å½¢å›¾
    fig = px.bar(
        plot_data,
        x='rank_change',
        y='åç§°',
        color='rank_change',
        color_continuous_scale=['#0068c9', '#FFFFFF', '#f63366'],  # è“ç™½çº¢è‰²
        range_color=[-max(abs(plot_data['rank_change'])), max(abs(plot_data['rank_change']))],
        title=f"æœ€æ–°äº¤æ˜“æ—¥æ¿å—æ’åå˜åŒ– (æŒ‰{indicator})",
        labels={'rank_change': 'æ’åå˜åŒ–', 'åç§°': 'æ¿å—åç§°'},
        height=400,
    )
    
    fig.update_layout(
        xaxis_title="æ’åå˜åŒ–ï¼ˆæ­£å€¼è¡¨ç¤ºä¸Šå‡ï¼‰",
        yaxis_title="",
        xaxis={'side': 'top'},
        margin=dict(l=10, r=10, t=40, b=10),
    )
    
    return fig

def normalize_date(date_value):
    """å°†å„ç§æ ¼å¼çš„æ—¥æœŸå€¼æ ‡å‡†åŒ–ä¸º 'YYYY-MM-DD' æ ¼å¼çš„å­—ç¬¦ä¸²"""
    try:
        # å¤„ç† datetime.date å¯¹è±¡
        if isinstance(date_value, datetime.date):
            return date_value.strftime('%Y-%m-%d')
        
        # å¤„ç† pandas Timestamp å¯¹è±¡
        elif isinstance(date_value, pd.Timestamp):
            return date_value.strftime('%Y-%m-%d')
        
        # å¤„ç†å­—ç¬¦ä¸²æ ¼å¼
        elif isinstance(date_value, str):
            parsed_date = pd.to_datetime(date_value)
            return parsed_date.strftime('%Y-%m-%d')
        
        # å¤„ç†å…¶ä»–ç±»å‹ï¼ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²åè§£æï¼‰
        else:
            parsed_date = pd.to_datetime(str(date_value))
            return parsed_date.strftime('%Y-%m-%d')
    
    except Exception as e:
        raise ValueError(f"æ— æ³•å°†å€¼ '{date_value}' è½¬æ¢ä¸ºæœ‰æ•ˆæ—¥æœŸ: {str(e)}")

# åœ¨test_db_connectionå‡½æ•°ä¸‹æ–¹æ·»åŠ ä¸€ä¸ªæ–°å‡½æ•°
def deep_db_diagnostic():
    """æ‰§è¡Œæ•°æ®åº“æ·±åº¦è¯Šæ–­ï¼Œé’ˆå¯¹MySQLæ•°æ®åº“"""
    results = {"success": False, "details": [], "found_tables": []}
    
    try:
        # å°è¯•ç›´æ¥ä»backend.dbå¯¼å…¥
        try:
            from backend.db import db
            results["details"].append("âœ… æˆåŠŸå¯¼å…¥backend.dbæ¨¡å—")
            
            # å°è¯•æ‰§è¡Œç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
            try:
                version_query = "SELECT VERSION() as version"
                version_df = db.query_to_dataframe(version_query)
                if not version_df.empty:
                    version = version_df['version'].iloc[0]
                    results["details"].append(f"âœ… æˆåŠŸè¿æ¥åˆ°MySQLæ•°æ®åº“ï¼Œç‰ˆæœ¬: {version}")
                    results["success"] = True
                else:
                    results["details"].append("âŒ æ— æ³•è·å–MySQLç‰ˆæœ¬")
            except Exception as e:
                results["details"].append(f"âŒ è¿æ¥æ•°æ®åº“å¤±è´¥: {str(e)}")
                
            # å°è¯•è·å–æ‰€æœ‰è¡¨å
            try:
                tables_query = "SHOW TABLES"
                tables_df = db.query_to_dataframe(tables_query)
                if not tables_df.empty:
                    # è¡¨ååœ¨ç¬¬ä¸€åˆ—ï¼Œä½†åˆ—åå¯èƒ½ä¸åŒ
                    first_col = tables_df.columns[0]
                    tables = tables_df[first_col].tolist()
                    results["details"].append(f"âœ… æ‰¾åˆ°{len(tables)}ä¸ªè¡¨: {tables}")
                    results["found_tables"] = tables
                else:
                    results["details"].append("âŒ æŸ¥è¯¢è¡¨åæˆåŠŸï¼Œä½†æ•°æ®åº“ä¸­æ²¡æœ‰è¡¨")
            except Exception as e:
                results["details"].append(f"âŒ è·å–è¡¨åå¤±è´¥: {str(e)}")
                
            # å°è¯•ç›´æ¥æŸ¥è¯¢ç‰¹å®šè¡¨
            target_tables = ["capital_flow", "CAPITAL_FLOW", "Capital_Flow", 
                           "sector_trend", "dde_analysis", "position_analysis"]
            
            for table in target_tables:
                try:
                    # åœ¨MySQLä¸­ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢
                    count_query = f"SELECT COUNT(*) as count FROM {table}"
                    count_df = db.query_to_dataframe(count_query)
                    if not count_df.empty:
                        count = count_df['count'].iloc[0]
                        results["details"].append(f"âœ… è¡¨ {table} å­˜åœ¨ï¼ŒåŒ…å« {count} æ¡è®°å½•")
                except Exception as e:
                    results["details"].append(f"âŒ æŸ¥è¯¢è¡¨ {table} å¤±è´¥: {str(e)}")
            
            # æ£€æŸ¥è¡¨ç»“æ„
            if "capital_flow" in results["found_tables"]:
                try:
                    struct_query = "DESCRIBE capital_flow"
                    struct_df = db.query_to_dataframe(struct_query)
                    if not struct_df.empty:
                        # è·å–å­—æ®µååˆ—è¡¨
                        fields = struct_df['Field'].tolist() if 'Field' in struct_df.columns else []
                        results["details"].append(f"âœ… capital_flowè¡¨åˆ—ä¿¡æ¯: {fields}")
                except Exception as e:
                    results["details"].append(f"âŒ è·å–è¡¨ç»“æ„å¤±è´¥: {str(e)}")
                
        except ImportError as e:
            results["details"].append(f"âŒ å¯¼å…¥backend.dbæ¨¡å—å¤±è´¥: {str(e)}")
            
    except Exception as e:
        results["details"].append(f"âŒ è¯Šæ–­è¿‡ç¨‹å‡ºé”™: {str(e)}")
    
    return results

def display_hot_sectors(dates, sector_data, selected_metric, show_limit=10, show_bottom=False):
    """
    æ˜¾ç¤ºçƒ­é—¨æ¿å—æ’è¡Œæ¦œï¼Œä½¿ç”¨ç®€æ´çš„è¡¨æ ¼å½¢å¼ï¼ˆç”¨æˆ·æŒ‡å®šçš„é¦–é€‰é£æ ¼ï¼‰
    
    Args:
        dates: æ—¥æœŸåˆ—è¡¨
        sector_data: æ¿å—æ•°æ®DataFrame
        selected_metric: é€‰æ‹©çš„æ’åºæŒ‡æ ‡
        show_limit: æ˜¾ç¤ºçš„æ’åæ•°é‡é™åˆ¶
        show_bottom: æ˜¯å¦æ˜¾ç¤ºå«åº•çš„æ¿å—ï¼ˆè€Œéæ’åé å‰çš„ï¼‰
    """
    
    if sector_data.empty:
        st.warning("æ²¡æœ‰å¯æ˜¾ç¤ºçš„æ¿å—æ•°æ®")
        return
    
    # æ·»åŠ è°ƒè¯•è¾“å‡º
    if st.checkbox("æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯", value=False):
        st.write("åŸå§‹æ•°æ®é¢„è§ˆï¼š")
        st.dataframe(sector_data.head())
    
    # ç¡®ä¿æ•°å€¼åˆ—ä¸ºæ•°å€¼ç±»å‹
    numeric_cols = ['ä¸»åŠ›å‡€æµå…¥', 'æ¶¨å¹…_pct', 'æ¶¨å¹…%', 'æˆäº¤é¢', 'æµå…¥èµ„é‡‘', 'æµå‡ºèµ„é‡‘', 'indicator_value']
    for col in numeric_cols:
        if col in sector_data.columns:
            sector_data[col] = pd.to_numeric(sector_data[col], errors='coerce')
    
    # ç¡®ä¿æ—¥æœŸåˆ—ä¸ºæ—¥æœŸç±»å‹ï¼Œå¹¶å¤„ç†æ—¥æœŸæ ¼å¼é—®é¢˜
    if 'æ•°æ®æ—¥æœŸ' in sector_data.columns:
        # æŠŠæ—¥æœŸè½¬æ¢æˆå­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿åç»­å¤„ç†
        sector_data['æ•°æ®æ—¥æœŸ_str'] = sector_data['æ•°æ®æ—¥æœŸ'].astype(str)
    
    # å¤„ç†æ¯ä¸ªæ—¥æœŸçš„æ•°æ®å¹¶æ„å»ºæ—¥æœŸä¸æ’åæ•°æ®çš„æ˜ å°„
    date_rank_data = {}
    
    for date in dates:
        date_str = str(date)
        date_obj = pd.to_datetime(date).date() if isinstance(date, str) else date
        date_obj_str = str(date_obj)
        
        # æ£€æŸ¥ä¸åŒçš„æ—¥æœŸæ ¼å¼
        date_formats = [
            date_str,
            date_obj_str,
            date_str.split()[0] if ' ' in date_str else date_str,  # å¤„ç†æœ‰æ—¶é—´éƒ¨åˆ†çš„æ—¥æœŸ
            date_obj_str.split()[0] if ' ' in date_obj_str else date_obj_str,
        ]
        
        # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼åŒ¹é…
        found = False
        date_data = None
        for fmt in date_formats:
            # é€šè¿‡å­—ç¬¦ä¸²æ¯”è¾ƒåŒ¹é…æ—¥æœŸ
            if 'æ•°æ®æ—¥æœŸ_str' in sector_data.columns:
                date_filter = sector_data['æ•°æ®æ—¥æœŸ_str'].str.startswith(fmt)
                if date_filter.any():
                    date_data = sector_data[date_filter].copy()
                    found = True
                    break
        
        # å¦‚æœä¸Šé¢çš„åŒ¹é…éƒ½å¤±è´¥ï¼Œå°è¯•ç›´æ¥ç”¨å¯¹è±¡åŒ¹é…
        if not found and 'æ•°æ®æ—¥æœŸ' in sector_data.columns:
            date_data = sector_data[sector_data['æ•°æ®æ—¥æœŸ'] == date_obj].copy()
        
        if date_data is None or date_data.empty:
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            if st.checkbox("æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯", value=False):
                st.warning(f"æ‰¾ä¸åˆ°æ—¥æœŸ {date} çš„æ•°æ®")
            continue
        
        # æ ¹æ®æŒ‡æ ‡æ’åº
        target_metric = selected_metric
        if target_metric not in date_data.columns and 'indicator_value' in date_data.columns:
            target_metric = 'indicator_value'
            
        if target_metric in date_data.columns:
            # ç¡®å®šæ’åºæ–¹å‘ï¼šå¦‚æœæ˜¯æ˜¾ç¤ºåº•éƒ¨æ’åä¸”æ˜¯èµ„é‡‘æµæŒ‡æ ‡ï¼ŒæŒ‰æŒ‡æ ‡å€¼ä»å°åˆ°å¤§æ’åº
            if show_bottom and ("æµå…¥" in selected_metric or "é‡‘é¢" in selected_metric):
                # å¯¹äºèµ„é‡‘ç±»æŒ‡æ ‡ï¼Œè´Ÿå€¼è¶Šå¤§ï¼ˆå¦‚-5.18äº¿ï¼‰è¡¨ç¤ºèµ„é‡‘æµå‡ºè¶Šå¤š
                date_data = date_data.sort_values(by=target_metric, ascending=True).reset_index(drop=True)
                # æ·»åŠ æ’åï¼ˆä»1å¼€å§‹ï¼Œè¡¨ç¤ºå€’æ•°ç¬¬ä¸€åï¼‰
                date_data['æ’å'] = range(1, len(date_data) + 1)
                date_data['æ’åç±»å‹'] = 'bottom'  # æ ‡è®°ä¸ºåº•éƒ¨æ’å
            elif show_bottom:
                # å¯¹äºå…¶ä»–æŒ‡æ ‡ï¼ŒæŒ‰æŒ‡æ ‡å€¼ä»å°åˆ°å¤§æ’åº
                date_data = date_data.sort_values(by=target_metric, ascending=True).reset_index(drop=True)
                # æ·»åŠ æ’åï¼ˆä»1å¼€å§‹ï¼Œè¡¨ç¤ºå€’æ•°ç¬¬ä¸€åï¼‰
                date_data['æ’å'] = range(1, len(date_data) + 1)
                date_data['æ’åç±»å‹'] = 'bottom'  # æ ‡è®°ä¸ºåº•éƒ¨æ’å
            else:
                # æ­£å¸¸æ’åºï¼šæŒ‡æ ‡å€¼ä»å¤§åˆ°å°
                date_data = date_data.sort_values(by=target_metric, ascending=False).reset_index(drop=True)
                # æ·»åŠ æ’åï¼ˆä»1å¼€å§‹ï¼Œè¡¨ç¤ºç¬¬ä¸€åï¼‰
                date_data['æ’å'] = range(1, len(date_data) + 1)
                date_data['æ’åç±»å‹'] = 'top'  # æ ‡è®°ä¸ºé¡¶éƒ¨æ’å
            
            # ç²¾ç®€æ•°æ®ï¼Œä»…ä¿ç•™å¿…è¦å­—æ®µ
            keep_cols = ['æ’å', 'æ’åç±»å‹', 'ä»£ç ', 'åç§°', target_metric]
            keep_cols = [col for col in keep_cols if col in date_data.columns]
            
            # å°†åˆ—åç»Ÿä¸€
            date_data = date_data[keep_cols].copy()
            if 'ä»£ç ' in date_data.columns:
                date_data.rename(columns={'ä»£ç ': 'æ¿å—ä»£ç '}, inplace=True)
            if 'åç§°' in date_data.columns:
                date_data.rename(columns={'åç§°': 'æ¿å—åç§°'}, inplace=True)
            if target_metric in date_data.columns:
                date_data.rename(columns={target_metric: 'æŒ‡æ ‡å€¼'}, inplace=True)
            
            # ä»…ä¿ç•™å‰Nåæˆ–åNå
            date_data = date_data.head(show_limit)
            
            # å­˜å‚¨æ—¥æœŸæ•°æ®
            date_rank_data[date_obj] = date_data
    
    if not date_rank_data:
        st.warning("æ²¡æœ‰å¯æ˜¾ç¤ºçš„æ’åæ•°æ®")
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        if st.checkbox("æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯", value=False):
            st.write("å°è¯•çš„æ—¥æœŸæ ¼å¼:")
            for date in dates:
                st.write(f" - {date} (ç±»å‹: {type(date)})")
            
            if 'æ•°æ®æ—¥æœŸ' in sector_data.columns:
                st.write("æ•°æ®åº“ä¸­å­˜åœ¨çš„æ—¥æœŸ:")
                unique_dates = sector_data['æ•°æ®æ—¥æœŸ'].unique()
                for date in unique_dates[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªï¼Œé¿å…è¿‡å¤š
                    st.write(f" - {date} (ç±»å‹: {type(date)})")
        return
    
    # æ˜¾ç¤ºæ ‡é¢˜
    if show_bottom:
        st.subheader(f"æŒ‰{selected_metric}æ’åºçš„è¡¨ç°æœ€å¼±æ¿å—")
    else:
        st.subheader(f"æŒ‰{selected_metric}æ’åºçš„çƒ­é—¨æ¿å—")
    
    # åˆ›å»ºç®€æ´è§†å›¾è¡¨æ ¼
    create_simple_rank_table(date_rank_data, dates, selected_metric, show_limit, show_bottom)


def create_simple_rank_table(date_rank_data, dates, metric_name, show_limit=10, show_bottom=False):
    """
    åˆ›å»ºç®€æ´çš„æ’åè¡¨æ ¼ï¼Œå®Œå…¨ä½¿ç”¨StreamlitåŸç”Ÿç»„ä»¶
    
    Args:
        date_rank_data: æ—¥æœŸä¸æ’åæ•°æ®çš„æ˜ å°„
        dates: æ—¥æœŸåˆ—è¡¨
        metric_name: æŒ‡æ ‡åç§°
        show_limit: æ˜¾ç¤ºçš„æœ€å¤§æ’åæ•°
        show_bottom: æ˜¯å¦æ˜¾ç¤ºå«åº•çš„æ¿å—
    """
    # æŒ‰æ—¥æœŸå€’åºæ’åˆ—(æœ€æ–°æ—¥æœŸåœ¨å‰)
    sorted_dates = sorted(dates, reverse=True)
    # æ˜¾ç¤ºæ‰€æœ‰æ—¥æœŸ
    display_dates = sorted_dates
    
    # å¦‚æœæ—¥æœŸå¤ªå¤šï¼Œæ·»åŠ ä¸€ä¸ªæç¤º
    if len(display_dates) > 10:
        st.info(f"æ­£åœ¨æ˜¾ç¤ºå…¨éƒ¨ {len(display_dates)} åˆ—æ•°æ®ï¼Œæ‚¨å¯ä»¥æ°´å¹³æ»šåŠ¨æŸ¥çœ‹æ‰€æœ‰æ—¥æœŸã€‚")
    
    # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰æ•°æ®çš„è¡¨æ ¼æ•°æ®ç»“æ„
    all_data_frames = []
    
    # å¤„ç†æ¯ä¸ªæ—¥æœŸçš„æ•°æ®ï¼Œå°†å®ƒä»¬æ”¶é›†åˆ°ä¸€ä¸ªåˆ—è¡¨ä¸­
    for i, date in enumerate(display_dates):
        # ç¡®ä¿ç”Ÿæˆå”¯ä¸€çš„æ—¥æœŸæ ‡è¯†ç¬¦ï¼ŒåŒ…å«æ—¥æœŸå’Œç´¢å¼•
        date_str = date.strftime('%m-%d') if hasattr(date, 'strftime') else str(date)
        # ä»æ—¥æœŸå­—ç¬¦ä¸²ä¸­æå–æœˆ-æ—¥éƒ¨åˆ†ï¼Œå¦‚æœæ ¼å¼ä¸ºYYYY-MM-DD
        if not hasattr(date, 'strftime') and len(date_str) >= 10 and '-' in date_str:
            try:
                # å°è¯•ä»YYYY-MM-DDæ ¼å¼æå–MM-DD
                date_str = date_str[5:10]  # æå–MM-DDéƒ¨åˆ†
            except:
                pass  # å¦‚æœå¤±è´¥ï¼Œä¿ç•™åŸå§‹æ ¼å¼
                
        short_date = f"{date_str}_{i}"  # æ·»åŠ ç´¢å¼•ç¡®ä¿å”¯ä¸€æ€§
        
        # æŸ¥æ‰¾æ­¤æ—¥æœŸçš„æ•°æ®
        date_data = None
        for key, value in date_rank_data.items():
            if (isinstance(key, (datetime.date, pd.Timestamp)) and 
                isinstance(date, (datetime.date, pd.Timestamp)) and
                key == date):
                date_data = value
                break
            elif str(key).startswith(str(date)) or str(date).startswith(str(key)):
                date_data = value
                break
        
        if date_data is not None:
            # åˆ›å»ºè¿™ä¸ªæ—¥æœŸçš„DataFrame
            temp_df = date_data.copy()
            # ä»…ä¿ç•™æ’åå’Œæ¿å—åç§°ã€æŒ‡æ ‡å€¼å’Œç±»å‹ä¿¡æ¯
            if 'æ¿å—åç§°' in temp_df.columns and 'æŒ‡æ ‡å€¼' in temp_df.columns:
                # å°†æŒ‡æ ‡å€¼æ ¼å¼åŒ–
                temp_df['value_str'] = temp_df['æŒ‡æ ‡å€¼'].apply(
                    lambda x: f"{x:.2f}äº¿" if "æµå…¥" in metric_name or "é‡‘é¢" in metric_name 
                    else (f"{x:.2f}%" if "%" in metric_name else f"{x:.2f}")
                )
                # æ·»åŠ æ•°å€¼çš„æ­£è´Ÿæ ‡è®°
                temp_df['value_sign'] = temp_df['æŒ‡æ ‡å€¼'].apply(lambda x: "positive" if x >= 0 else "negative")
                
                # ä½¿ç”¨å”¯ä¸€åˆ—å
                temp_df[f'æ¿å—_{short_date}'] = temp_df['æ¿å—åç§°']
                temp_df[f'å€¼_{short_date}'] = temp_df['value_str']
                temp_df[f'ç¬¦å·_{short_date}'] = temp_df['value_sign']
                temp_df[f'ç±»å‹_{short_date}'] = temp_df['æ’åç±»å‹']
                
                # ä¿ç•™å¿…è¦å­—æ®µï¼Œåªä¿ç•™æ’åå’Œæ–°åˆ›å»ºçš„å¸¦æ—¥æœŸåˆ—åçš„åˆ—
                columns_to_keep = ['æ’å']
                columns_to_keep.extend([
                    f'æ¿å—_{short_date}', 
                    f'å€¼_{short_date}', 
                    f'ç¬¦å·_{short_date}', 
                    f'ç±»å‹_{short_date}'
                ])
                
                if f'å€’æ•°æ’å_{short_date}' in temp_df.columns:
                    columns_to_keep.append(f'å€’æ•°æ’å_{short_date}')
                
                temp_df = temp_df[columns_to_keep]
                
                # å°†å¤„ç†åçš„DataFrameæ·»åŠ åˆ°åˆ—è¡¨ä¸­
                all_data_frames.append(temp_df)
    
    # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºå¹¶è¿”å›
    if not all_data_frames:
        st.warning("æ— æ³•ç”Ÿæˆè¡¨æ ¼ï¼šæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ•°æ®")
        return
    
    # ä»ç¬¬ä¸€ä¸ªDataFrameå¼€å§‹ï¼Œä¾æ¬¡åˆå¹¶å…¶ä½™çš„DataFrame
    df_merged = all_data_frames[0]
    for df in all_data_frames[1:]:
        df_merged = pd.merge(df_merged, df, on='æ’å', how='outer', suffixes=(False, False))
    
    # æŒ‰æ’åæ’åº
    df_merged = df_merged.sort_values('æ’å')
    
    # åˆ›å»ºä¸€ä¸ªå®¹å™¨å¹¶æ·»åŠ CSSä»¥æ”¯æŒæ°´å¹³æ»šåŠ¨
    st.markdown("""
    <style>
    .scrollable-container {
        width: 100%;
        overflow-x: auto;
        white-space: nowrap;
    }
    .bottom-rank-marker {
        font-size: 10px;
        color: #666666;
        position: absolute;
        top: -5px;
        right: -5px;
        background-color: #f0f0f0;
        border-radius: 50%;
        width: 16px;
        height: 16px;
        line-height: 16px;
        text-align: center;
        display: flex;
        align-items: center;
        justify-content: center;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # 1. ä½¿ç”¨å¯æ»šåŠ¨å®¹å™¨åŒ…è£…è¡¨æ ¼
    st.markdown('<div class="scrollable-container">', unsafe_allow_html=True)
    
    # åˆ›å»ºè¡¨æ ¼å®¹å™¨
    with st.container():
        # åˆ›å»ºä¸€ä¸ªè¡¨æ ¼å±•ç¤ºåŒºåŸŸ
        col_count = len(display_dates) + 1  # æ’ååˆ— + æ—¥æœŸåˆ—
        columns = st.columns(col_count)
        
        # æ·»åŠ è¡¨å¤´
        with columns[0]:
            if show_bottom:
                st.markdown("<div style='text-align: center; font-weight: bold;'>å€’æ•°</div>", unsafe_allow_html=True)
            else:
                st.markdown("<div style='text-align: center; font-weight: bold;'>æ’å</div>", unsafe_allow_html=True)
        
        for i, date in enumerate(display_dates):
            # ä¿®æ”¹è¿™é‡Œçš„æ—¥æœŸæ ¼å¼åŒ–é€»è¾‘ï¼Œåªæ˜¾ç¤ºæœˆ-æ—¥ï¼Œä¸æ˜¾ç¤ºå¹´ä»½
            if hasattr(date, 'strftime'):
                display_date = date.strftime('%m-%d')  # åªæ˜¾ç¤ºæœˆ-æ—¥
            else:
                # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æœˆ-æ—¥éƒ¨åˆ†
                try:
                    date_str = str(date)
                    if len(date_str) >= 10 and '-' in date_str:
                        # å¯¹äºYYYY-MM-DDæ ¼å¼
                        display_date = date_str[5:10]  # æå–MM-DDéƒ¨åˆ†
                    else:
                        date_obj = pd.to_datetime(date)
                        display_date = date_obj.strftime('%m-%d')
                except:
                    display_date = str(date)
                    # å¦‚æœæ˜¯YYYY-MM-DDæ ¼å¼ï¼Œåªä¿ç•™MM-DDéƒ¨åˆ†
                    if len(display_date) >= 10 and '-' in display_date:
                        display_date = display_date[5:10]
            
            with columns[i+1]:
                st.markdown(f"<div style='text-align: center; font-weight: bold;'>{display_date}</div>", unsafe_allow_html=True)
        
        # æ·»åŠ åˆ†éš”çº¿
        st.markdown("<hr style='margin: 5px 0;'>", unsafe_allow_html=True)
        
        # æ ‡å‡†æ¨¡å¼ - æ˜¾ç¤ºæ‰€æœ‰æ’å
        for idx, row in df_merged.iterrows():
            rank = int(row['æ’å'])
            if rank > show_limit:
                continue
                
            cols = st.columns(col_count)
            
            # æ’ååˆ— - ä½¿ç”¨è‡ªå®šä¹‰HTMLæ˜¾ç¤ºå¸¦é¢œè‰²çš„æ’å
            with cols[0]:
                if show_bottom:
                    # ä½¿ç”¨ç°è‰²ç³»åˆ—è¡¨ç¤ºå€’æ•°æ’å
                    if rank <= 3:
                        color = ["#767676", "#888888", "#999999"][rank-1]  # æ·±ç°ã€ç°ã€æµ…ç°
                    else:
                        color = "#aaaaaa"  # æ™®é€šç°è‰²
                    # æ·»åŠ å‘ä¸‹ç®­å¤´æ ‡è®°
                    st.markdown(f"""
                    <div style='display: flex; justify-content: center; align-items: center; position: relative;'>
                        <div style='width: 30px; height: 30px; border-radius: 50%; background-color: {color}; 
                        color: white; display: flex; align-items: center; justify-content: center; 
                        font-weight: bold; font-size: 18px;'>{rank}</div>
                        <div style='font-size: 10px; color: #666666; position: absolute; 
                        top: -5px; right: -5px; background-color: #f0f0f0; border-radius: 50%; 
                        width: 16px; height: 16px; line-height: 16px; text-align: center;
                        display: flex; align-items: center; justify-content: center;'>â†“</div>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    # æ­£å¸¸æ’åä½¿ç”¨å½©è‰²æ ‡è®°
                    if rank <= 3:
                        color = ["#FF4B4B", "#FF8F65", "#FFCA3A"][rank-1]  # çº¢ã€æ©™ã€é»„
                    else:
                        color = "#f44336"  # æ™®é€šçº¢è‰²
                    st.markdown(f"""
                    <div style='display: flex; justify-content: center; align-items: center;'>
                        <div style='width: 30px; height: 30px; border-radius: 50%; background-color: {color}; 
                        color: white; display: flex; align-items: center; justify-content: center; 
                        font-weight: bold; font-size: 18px;'>{rank}</div>
                    </div>
                    """, unsafe_allow_html=True)
            
            # æ—¥æœŸæ•°æ®åˆ—
            for i, date in enumerate(display_dates):
                # æå–æœˆ-æ—¥æ ¼å¼
                if hasattr(date, 'strftime'):
                    date_str = date.strftime('%m-%d')
                else:
                    date_str = str(date)
                    if len(date_str) >= 10 and '-' in date_str:
                        date_str = date_str[5:10]
                short_date = f"{date_str}_{i}"  # ä¸ä¸Šé¢ç”Ÿæˆåˆ—åçš„æ–¹å¼ä¿æŒä¸€è‡´
                
                with cols[i+1]:
                    board_col = f'æ¿å—_{short_date}'
                    value_col = f'å€¼_{short_date}'
                    sign_col = f'ç¬¦å·_{short_date}'
                    
                    if (board_col in row and value_col in row and sign_col in row and 
                        pd.notna(row[board_col]) and pd.notna(row[value_col])):
                        board_name = row[board_col]
                        value = row[value_col]
                        is_positive = row[sign_col] == "positive"
                        
                        # æ ¹æ®å€¼çš„æ­£è´Ÿé€‰æ‹©é¢œè‰²ï¼šæ­£æ•°çº¢è‰²ï¼Œè´Ÿæ•°ç»¿è‰²
                        # å¯¹äºå€’æ•°æ’åæ¿å—ï¼Œå¯ä»¥ä½¿ç”¨è¾ƒæš—çš„é¢œè‰²
                        if show_bottom:
                            value_color = "#de5246" if is_positive else "#359e35"  # æš—çº¢è‰²/æš—ç»¿è‰²
                        else:
                            value_color = "#ff4b4b" if is_positive else "#0bbd0b"  # äº®çº¢è‰²/äº®ç»¿è‰²
                        
                        st.markdown(f"""
                        <div style='text-align: center;'>
                            <div style='font-size: 14px; margin-bottom: 5px;'>{board_name}</div>
                            <div style='font-size: 16px; font-weight: bold; color: {value_color};'>{value}</div>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown("<div style='text-align: center;'>-</div>", unsafe_allow_html=True)
            
            # æ·»åŠ æµ…è‰²åˆ†éš”çº¿
            st.markdown("<hr style='margin: 5px 0; border-color: #f0f0f0;'>", unsafe_allow_html=True)
    
    # å…³é—­å¯æ»šåŠ¨å®¹å™¨
    st.markdown('</div>', unsafe_allow_html=True)
    
    # æ˜¾ç¤ºæ—¥æœŸåˆ°æ•°æ®æ˜ å°„çš„è°ƒè¯•ä¿¡æ¯
    if st.checkbox("æ˜¾ç¤ºæ•°æ®æ˜ å°„è°ƒè¯•", value=False):
        st.write("æ—¥æœŸåˆ°æ•°æ®çš„æ˜ å°„:")
        for date, data in date_rank_data.items():
            st.write(f"æ—¥æœŸ: {date} (ç±»å‹: {type(date)})")
            st.dataframe(data.head(3))

def main():
    # ä¾§è¾¹æ ï¼šæ‰€æœ‰é…ç½®é€‰é¡¹
    with st.sidebar:
        st.header("ğŸ“Š æ•°æ®è®¾ç½®")
        
        # æ·»åŠ æ¿å—ç±»å‹è¿‡æ»¤é€‰é¡¹
        st.markdown("### æ¿å—ç±»å‹")
        board_type_options = {
            "æ¦‚å¿µæ¿å—": "æ¦‚å¿µ", 
            "è¡Œä¸šæ¿å—": "è¡Œä¸š", 
            "åœ°åŒºæ¿å—": "åœ°åŒº", 
            "é£æ ¼æ¿å—": "é£æ ¼",
            "å…¨éƒ¨æ¿å—": None
        }
        selected_board_type_display = st.selectbox(
            "é€‰æ‹©æ¿å—ç±»å‹", 
            list(board_type_options.keys()),
            index=0  # é»˜è®¤é€‰æ‹©"æ¦‚å¿µæ¿å—"
        )
        selected_board_type = board_type_options[selected_board_type_display]
        
        # è·å–æŒ‡æ ‡åˆ—è¡¨å¹¶æä¾›é€‰æ‹©ï¼ˆä¸‹æ‹‰å¼ï¼‰
        all_indicators = get_all_indicators()
        
        # æŒ‰è¡¨åˆ†ç»„æŒ‡æ ‡
        grouped_indicators = {
            "èµ„é‡‘æµæŒ‡æ ‡ (capital_flow)": [k for k, v in all_indicators.items() if v["table"] == "capital_flow"],
            "DDEæŒ‡æ ‡ (dde_analysis)": [k for k, v in all_indicators.items() if v["table"] == "dde_analysis"],
            "å¢ä»“æŒ‡æ ‡ (position_analysis)": [k for k, v in all_indicators.items() if v["table"] == "position_analysis"],
            "æ¿å—è¶‹åŠ¿ (sector_trend)": [k for k, v in all_indicators.items() if v["table"] == "sector_trend"],
        }
        
        # é€‰æ‹©æŒ‡æ ‡åˆ†ç»„
        selected_group = st.selectbox(
            "é€‰æ‹©æŒ‡æ ‡åˆ†ç»„",
            list(grouped_indicators.keys()),
            index=0
        )
        
        # æ ¹æ®é€‰æ‹©çš„åˆ†ç»„æ˜¾ç¤ºç›¸åº”çš„æŒ‡æ ‡
        group_indicators = grouped_indicators[selected_group]
        
        selected_indicator = st.selectbox(
            "é€‰æ‹©æŒ‡æ ‡", 
            group_indicators,
            index=0,
            format_func=lambda x: f"{x} ({all_indicators[x]['unit']})" if all_indicators[x]['unit'] else x
        )
        
        # æ·»åŠ æ—¥æœŸé€‰æ‹©ç•Œé¢
        st.markdown("### æ—¥æœŸè®¾ç½®")
        
        # æ—¥æœŸèŒƒå›´é€‰æ‹©ï¼ˆä¸‹æ‹‰å¼ï¼‰
        date_options = {"æœ€è¿‘5æ—¥": 5, "æœ€è¿‘10æ—¥": 10, "æœ€è¿‘30æ—¥": 30, "æœ€è¿‘60æ—¥": 60}
        date_range = st.selectbox("æ—¥æœŸèŒƒå›´", list(date_options.keys()), index=1)
        days_count = date_options[date_range]
        
        # è·å–äº¤æ˜“æ—¥æœŸï¼ˆè‡ªåŠ¨æ–¹å¼ï¼‰
        status_container = st.empty()
        dates = get_recent_trading_dates(days=days_count)
        if dates:
            add_debug_message(f"æˆåŠŸè·å– {len(dates)} ä¸ªäº¤æ˜“æ—¥æœŸ", "success")
        else:
            add_debug_message("æ— æ³•è·å–äº¤æ˜“æ—¥æœŸæ•°æ®", "error")
            current_date = pd.Timestamp.now()
            dates = [(current_date - pd.Timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days_count)]
        
        # æ˜¾ç¤ºèŒƒå›´ï¼ˆä¸‹æ‹‰å¼ï¼‰
        st.markdown("### æ˜¾ç¤ºèŒƒå›´")
        rank_options = [
            "å‰10å", "å‰20å", "å‰30å", "å‰50å",
            "å10å", "å20å", "å30å",
            "å…¨éƒ¨"
        ]
        rank_display = st.selectbox("æ˜¾ç¤ºèŒƒå›´", rank_options, index=0)
        
        # è§£ææ˜¾ç¤ºèŒƒå›´ï¼Œè®¾ç½®show_limitå’Œshow_bottom
        show_bottom = False
        if rank_display == "å‰10å":
            show_limit = 10
        elif rank_display == "å‰20å":
            show_limit = 20
        elif rank_display == "å‰30å":
            show_limit = 30
        elif rank_display == "å‰50å":
            show_limit = 50
        elif rank_display == "å10å":
            show_limit = 10
            show_bottom = True
        elif rank_display == "å20å":
            show_limit = 20
            show_bottom = True
        elif rank_display == "å30å":
            show_limit = 30
            show_bottom = True
        else:  # å…¨éƒ¨
            show_limit = 100
        
        # æ·»åŠ æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯çš„é€‰é¡¹
        show_debug = st.checkbox("æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯", value=False,
                               help="é€‰ä¸­æ­¤é¡¹å°†æ˜¾ç¤ºè¯¦ç»†çš„æŸ¥è¯¢è¿‡ç¨‹å’Œé”™è¯¯ä¿¡æ¯")
    
    # éªŒè¯æ—¥æœŸæ ¼å¼ï¼Œè¿‡æ»¤æ‰æ— æ•ˆæ—¥æœŸ
    valid_dates = []
    for date in dates:
        try:
            # å°è¯•æ ‡å‡†åŒ–æ—¥æœŸ
            normalized_date = normalize_date(date)
            valid_dates.append(normalized_date)
        except Exception as e:
            add_debug_message(f"æ—¥æœŸ {date} æ ¼å¼æ— æ•ˆï¼Œå·²è·³è¿‡: {str(e)}", "warning")
            continue
    
    if not valid_dates:
        st.error("âš ï¸ æ‰€æœ‰æ—¥æœŸå‡æ— æ•ˆï¼Œæ— æ³•è·å–æ•°æ®")
        if show_debug:
            display_debug_messages()
        return
    
    dates = valid_dates
    
    # æ˜¾ç¤ºæœ‰æ•ˆçš„æ—¥æœŸåˆ—è¡¨åˆ°è°ƒè¯•åŒº
    add_debug_message(f"æœ‰æ•ˆæ—¥æœŸåˆ—è¡¨: {dates}", "info")
    
    # å¦‚æœé€‰æ‹©äº†æ¿å—ç±»å‹ï¼Œæ·»åŠ åˆ°è°ƒè¯•ä¿¡æ¯
    if selected_board_type:
        add_debug_message(f"æ¿å—ç±»å‹è¿‡æ»¤: {selected_board_type}", "info")
         
    # è·å–æ‰€é€‰æŒ‡æ ‡çš„æ•°æ®
    indicator_info = all_indicators[selected_indicator]
    add_debug_message(f"æ­£åœ¨è·å–æŒ‡æ ‡æ•°æ®: {selected_indicator} (è¡¨: {indicator_info['table']})", "info")
    
    # ä»æ•°æ®åº“è·å–æ•°æ®
    add_debug_message("ä»æ•°æ®åº“è·å–æ•°æ®...", "info")
    # ä¼ é€’show_bottomå‚æ•°å’Œboard_typeå‚æ•°åˆ°get_hot_sectorså‡½æ•°
    hot_sectors_data = get_hot_sectors(
        indicator_info, 
        dates, 
        rank_limit=100, 
        get_bottom=show_bottom,
        board_type=selected_board_type
    )
    
    if hot_sectors_data.empty:
        st.error(f"âš ï¸ æœªèƒ½è·å–åˆ°\"{selected_indicator}\"çš„æ•°æ®")
        st.info("å¯èƒ½çš„åŸå› ï¼š")
        st.info("1. æ•°æ®åº“ä¸­ä¸å­˜åœ¨è¯¥æŒ‡æ ‡çš„æ•°æ®")
        st.info("2. æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
        if selected_board_type:
            st.info(f"3. æ²¡æœ‰ç¬¦åˆ\"{selected_board_type_display}\"ç±»å‹çš„æ¿å—æ•°æ®")
        st.info("è¯·å°è¯•é€‰æ‹©å…¶ä»–æŒ‡æ ‡ã€æ—¥æœŸèŒƒå›´æˆ–æ¿å—ç±»å‹")
    else:
        add_debug_message(f"æˆåŠŸè·å– {len(hot_sectors_data)} æ¡æ•°æ®è®°å½•", "success")
        # ä¸»åŒºåŸŸï¼šæ˜¾ç¤ºæ’åè¡¨æ ¼
        display_hot_sectors(dates, hot_sectors_data, selected_indicator, show_limit, show_bottom)
    
    # æ·»åŠ æ•°æ®åº“å·¥å…·åˆ°é¡µé¢åº•éƒ¨
    st.markdown("---")  # åˆ†éš”çº¿
    with st.expander("æ•°æ®åº“å·¥å…·", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            # æ•°æ®åº“è¿æ¥æµ‹è¯•æŒ‰é’®
            if st.button("æµ‹è¯•æ•°æ®åº“è¿æ¥", type="primary", key="test_db_bottom"):
                with st.spinner("æ­£åœ¨æµ‹è¯•æ•°æ®åº“è¿æ¥..."):
                    db_info = test_db_connection()
                    if db_info["success"]:
                        st.success(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ: {db_info['connection_type']}")
                        if db_info["tables"]:
                            st.info(f"æ•°æ®åº“ä¸­çš„è¡¨: {db_info['tables']}")
                        else:
                            st.warning("æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°è¡¨")
                    else:
                        st.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {db_info['error']}")
                        if db_info["db_path"]:
                            st.info(f"æ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶: {db_info['db_path']}")
        
        with col2:
            # æ•°æ®åº“æ·±åº¦è¯Šæ–­æŒ‰é’®
            if st.button("æ•°æ®åº“æ·±åº¦è¯Šæ–­", type="secondary", key="deep_db_bottom"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œæ·±åº¦è¯Šæ–­..."):
                    diagnostic_results = deep_db_diagnostic()
                    for detail in diagnostic_results["details"]:
                        if detail.startswith("âœ…"):
                            st.success(detail)
                        elif detail.startswith("âŒ"):
                            st.error(detail)
                        else:
                            st.info(detail)
    
    # åœ¨é¡µé¢åº•éƒ¨æ˜¾ç¤ºæ”¶é›†çš„è°ƒè¯•ä¿¡æ¯
    if show_debug:
        display_debug_messages()

if __name__ == "__main__":
    main() 

# æ·»åŠ å…¨å±€æ‚¬æµ®åŠ©æ‰‹
try:
    add_global_assistant()
except Exception as e:
    print(f"Error adding global assistant: {e}")
