import streamlit as st
# å¯¼å…¥å…¨å±€åŠ©æ‰‹
try:
    from backend.helper import add_global_assistant
except ImportError:
    print("Error importing assistant helper")
import pandas as pd
from backend.db import db
from io import BytesIO

# é¡µé¢é…ç½®
st.set_page_config(page_title="æ¡ä»¶é€‰æ¿å—", page_icon="ğŸ“ˆ", layout="wide")

# é¡µé¢æ ‡é¢˜
st.title("ğŸ“ˆ æ¡ä»¶é€‰æ¿å—")

# å®šä¹‰å¯é€‰æ‹©çš„æ•°æ®è¡¨å’Œå¯¹åº”çš„ä¸­æ–‡åç§°
TABLES = {
    'capital_flow': 'èµ„é‡‘æµå‘',
    'dde_analysis': 'ä¸»åŠ›è¡Œä¸º',
    'position_analysis': 'æŒä»“åˆ†æ',
    'sector_trend': 'æ¿å—è¶‹åŠ¿',
    'market_trend': 'å¤§ç›˜è¶‹åŠ¿',
    'bk_type_mapping': 'æ¿å—ç±»å‹æ˜ å°„'
}

# å®šä¹‰æ¯ä¸ªè¡¨çš„å¯ç”¨å­—æ®µå’Œå¯¹åº”çš„ä¸­æ–‡åç§°
FIELDS = {
    'capital_flow': {
        'ä¸»åŠ›å‡€æµå…¥': 'ä¸»åŠ›å‡€æµå…¥',
        'è¶…å¤§å•å‡€é¢': 'è¶…å¤§å•å‡€é¢',
        'å¤§å•å‡€é¢': 'å¤§å•å‡€é¢',
        'ä¸­å•å‡€é¢': 'ä¸­å•å‡€é¢',
        'å°å•å‡€é¢': 'å°å•å‡€é¢',
        'è¶…å¤§å•æµå…¥': 'è¶…å¤§å•æµå…¥',
        'è¶…å¤§å•æµå‡º': 'è¶…å¤§å•æµå‡º',
        'è¶…å¤§å•å‡€å æ¯”%': 'è¶…å¤§å•å‡€å æ¯”%',
        'å¤§å•æµå…¥': 'å¤§å•æµå…¥',
        'å¤§å•æµå‡º': 'å¤§å•æµå‡º',
        'å¤§å•å‡€å æ¯”%': 'å¤§å•å‡€å æ¯”%',
        'ä¸­å•æµå…¥': 'ä¸­å•æµå…¥',
        'ä¸­å•æµå‡º': 'ä¸­å•æµå‡º',
        'ä¸­å•å‡€å æ¯”%': 'ä¸­å•å‡€å æ¯”%',
        'å°å•æµå…¥': 'å°å•æµå…¥',
        'å°å•æµå‡º': 'å°å•æµå‡º',
        'å°å•å‡€å æ¯”%': 'å°å•å‡€å æ¯”%'
    },
    'dde_analysis': {
        'DDX': 'DDXæŒ‡æ ‡',
        'DDY': 'DDYæŒ‡æ ‡',
        'DDZ': 'DDZæŒ‡æ ‡',
        '5æ—¥DDX': '5æ—¥DDX',
        '5æ—¥DDY': '5æ—¥DDY',
        '10æ—¥DDX': '10æ—¥DDX',
        '10æ—¥DDY': '10æ—¥DDY',
        'è¿ç»­': 'è¿ç»­',
        '5æ—¥å†…': '5æ—¥å†…',
        '10æ—¥å†…': '10æ—¥å†…',
        'ç‰¹å¤§ä¹°å…¥%': 'ç‰¹å¤§ä¹°å…¥æ¯”ä¾‹',
        'ç‰¹å¤§å–å‡º%': 'ç‰¹å¤§å–å‡ºæ¯”ä¾‹',
        'ç‰¹å¤§å•å‡€æ¯”%': 'ç‰¹å¤§å•å‡€æ¯”ä¾‹',
        'å¤§å•ä¹°å…¥%': 'å¤§å•ä¹°å…¥æ¯”ä¾‹',
        'å¤§å•å–å‡º%': 'å¤§å•å–å‡ºæ¯”ä¾‹',
        'å¤§å•å‡€æ¯”%': 'å¤§å•å‡€æ¯”ä¾‹'
    },
    'position_analysis': {
        'ä»Šæ—¥å¢ä»“å æ¯”': '1æ—¥å¢ä»“æ¯”ä¾‹',
        'ä»Šæ—¥æ’å': 'ä»Šæ—¥æ’å',
        'ä»Šæ—¥æ’åå˜åŒ–': 'ä»Šæ—¥æ’åå˜åŒ–',
        'ä»Šæ—¥æ¶¨å¹…%': 'ä»Šæ—¥æ¶¨å¹…',
        '3æ—¥å¢ä»“å æ¯”': '3æ—¥å¢ä»“æ¯”ä¾‹',
        '3æ—¥æ’å': '3æ—¥æ’å',
        '3æ—¥æ’åå˜åŒ–': '3æ—¥æ’åå˜åŒ–',
        '3æ—¥æ¶¨å¹…%': '3æ—¥æ¶¨å¹…',
        '5æ—¥å¢ä»“å æ¯”': '5æ—¥å¢ä»“æ¯”ä¾‹',
        '5æ—¥æ’å': '5æ—¥æ’å',
        '5æ—¥æ’åå˜åŒ–': '5æ—¥æ’åå˜åŒ–',
        '5æ—¥æ¶¨å¹…%': '5æ—¥æ¶¨å¹…',
        '10æ—¥å¢ä»“å æ¯”': '10æ—¥å¢ä»“æ¯”ä¾‹',
        '10æ—¥æ’å': '10æ—¥æ’å',
        '10æ—¥æ’åå˜åŒ–': '10æ—¥æ’åå˜åŒ–',
        '10æ—¥æ¶¨å¹…%': '10æ—¥æ¶¨å¹…'
    },
    'sector_trend': {
        'æ¶¨å¹…%': 'æ¶¨å¹…',
        '3æ—¥æ¶¨å¹…%': '3æ—¥æ¶¨å¹…',
        'æ¶¨é€Ÿ%': 'æ¶¨é€Ÿ',
        'é¢†æ¶¨è‚¡': 'é¢†æ¶¨è‚¡',
        'æ¶¨å®¶æ•°': 'æ¶¨å®¶æ•°',
        'è·Œå®¶æ•°': 'è·Œå®¶æ•°',
        'æ¶¨è·Œæ¯”': 'æ¶¨è·Œæ¯”',
        'æ¶¨åœå®¶æ•°': 'æ¶¨åœå®¶æ•°',
        'æ¢æ‰‹%': 'æ¢æ‰‹ç‡',
        '3æ—¥æ¢æ‰‹%': '3æ—¥æ¢æ‰‹ç‡',
        'æˆäº¤é‡': 'æˆäº¤é‡',
        'é‡‘é¢': 'æˆäº¤é‡‘é¢',
        'æ€»å¸‚å€¼': 'æ€»å¸‚å€¼',
        'æµé€šå¸‚å€¼': 'æµé€šå¸‚å€¼',
        'å¹³å‡æ”¶ç›Š': 'å¹³å‡æ”¶ç›Š',
        'å¹³å‡è‚¡æœ¬': 'å¹³å‡è‚¡æœ¬',
        'å¸‚ç›ˆç‡': 'å¸‚ç›ˆç‡'
    },
    'market_trend': {
        'close_price': 'æ”¶ç›˜ä»·',
        'change_ratio': 'æ¶¨è·Œå¹…',
        'turnover': 'æˆäº¤é¢',
        'high_price': 'æœ€é«˜ä»·',
        'low_price': 'æœ€ä½ä»·',
        'open_price': 'å¼€ç›˜ä»·',
        'pre_close': 'æ˜¨æ”¶ä»·'
    },
    'bk_type_mapping': {
        'board_type': 'æ¿å—ç±»å‹'
    }
}

# å®šä¹‰æ¡ä»¶è¿ç®—ç¬¦
OPERATORS = {
    '>': 'å¤§äº',
    '>=': 'å¤§äºç­‰äº',
    '<': 'å°äº',
    '<=': 'å°äºç­‰äº',
    '=': 'ç­‰äº',
    'continuous_>': 'è¿ç»­nå¤©å¤§äº',
    'continuous_>=': 'è¿ç»­nå¤©å¤§äºç­‰äº',
    'avg_>=': 'å¤§äºç­‰äºnæ—¥å‡å€¼',
    'avg_ratio_>=': 'å¤§äºç­‰äºnæ—¥å‡å€¼çš„må€'
}

def format_condition_summary(condition):
    """æ ¼å¼åŒ–å•ä¸ªæ¡ä»¶ä¸ºäººç±»å¯è¯»çš„æ–‡æœ¬"""
    table_name = TABLES[condition['table']]
    field_name = FIELDS[condition['table']][condition['field']]
    operator = OPERATORS[condition['operator']]
    
    if 'continuous_' in condition['operator']:
        return f"{table_name}çš„{field_name}è¿ç»­{condition['days']}å¤©{operator.replace('è¿ç»­nå¤©','')} {condition['value']}"
    elif 'avg_ratio_' in condition['operator']:
        return f"{table_name}çš„{field_name}{operator.replace('næ—¥å‡å€¼çš„må€','')} {condition['days']}æ—¥å‡å€¼çš„{condition['value']}å€"
    elif 'avg_' in condition['operator']:
        return f"{table_name}çš„{field_name}{operator.replace('næ—¥å‡å€¼','')} {condition['days']}æ—¥å‡å€¼"
    else:
        return f"{table_name}çš„{field_name} {operator} {condition['value']}"

def create_filter_area(area_name):
    """åˆ›å»ºç‹¬ç«‹çš„ç­›é€‰åŒºåŸŸ"""
    with st.expander(f"ğŸ“Š ç­›é€‰åŒº {area_name}", expanded=True):
        num_conditions = st.number_input(
            "æ¡ä»¶æ•°é‡",
            min_value=1,
            max_value=10,
            value=1,
            key=f"num_conditions_{area_name}"
        )
        
        conditions = []
        for i in range(num_conditions):
            st.markdown(f"##### æ¡ä»¶{i+1}")
            
            cols = st.columns([2, 2, 1.5, 1, 1])
            
            with cols[0]:
                table = st.selectbox(
                    f"é€‰æ‹©æ•°æ®è¡¨ #{i+1}",
                    options=list(TABLES.keys()),
                    format_func=lambda x: TABLES[x],
                    key=f'table_{area_name}_{i}'
                )
            
            with cols[1]:
                field = st.selectbox(
                    f"é€‰æ‹©å­—æ®µ #{i+1}",
                    options=list(FIELDS.get(table, {}).keys()),
                    format_func=lambda x: FIELDS[table][x],
                    key=f'field_{area_name}_{i}'
                )
            
            with cols[2]:
                operator = st.selectbox(
                    f"æ¡ä»¶ #{i+1}",
                    options=list(OPERATORS.keys()),
                    format_func=lambda x: OPERATORS[x],
                    key=f'operator_{area_name}_{i}',
                    index=0 if i > 0 else list(OPERATORS.keys()).index('continuous_>')
                )
            
            with cols[3]:
                if 'continuous_' in operator or 'avg_' in operator:
                    days = st.number_input(
                        "å¤©æ•°",
                        min_value=1,
                        value=3 if i == 0 else 1,
                        key=f'days_{area_name}_{i}'
                    )
                else:
                    days = 0
            
            with cols[4]:
                if 'avg_ratio_' in operator:
                    value = st.number_input(
                        "å€æ•°",
                        value=1.5,
                        step=0.1,
                        format='%f',
                        key=f'value_{area_name}_{i}'
                    )
                else:
                    value = st.number_input(
                        "æ•°å€¼",
                        value=0.0,
                        step=1.0,
                        format='%f',
                        key=f'value_{area_name}_{i}'
                    )
            
            conditions.append({
                'table': table,
                'field': field,
                'operator': operator,
                'days': days,
                'value': value
            })
        
        # å­˜å‚¨æ¡ä»¶åˆ°session state
        if 'filter_conditions' not in st.session_state:
            st.session_state.filter_conditions = {}
        st.session_state.filter_conditions[area_name] = conditions
        
        # æ˜¾ç¤ºæ¡ä»¶æ‘˜è¦
        if conditions:
            st.markdown("**ç­›é€‰æ¡ä»¶æ‘˜è¦:**")
            for i, condition in enumerate(conditions):
                st.markdown(f"- {format_condition_summary(condition)}")

def build_stock_query(conditions, board_type=None):
    """æ„å»ºè‚¡ç¥¨ç­›é€‰SQLæŸ¥è¯¢"""
    sub_queries = []
    detail_columns = []  # ç”¨äºå­˜å‚¨éœ€è¦æ˜¾ç¤ºçš„è¯¦ç»†åˆ—
    detail_joins = []    # ç”¨äºå­˜å‚¨éœ€è¦JOINçš„å­æŸ¥è¯¢
    has_sector_trend = False  # æ ‡è®°æ˜¯å¦ä½¿ç”¨äº†sector_trendè¡¨
    
    for i, condition in enumerate(conditions):
        table = condition['table']
        field = condition['field']
        operator = condition['operator']
        value = float(condition['value'])
        days = condition['days']
        
        # ä¸ºsector_trendè¡¨ä½¿ç”¨ç‰¹æ®Šå¤„ç†
        if table == "sector_trend":
            has_sector_trend = True
            
        # è¿ç»­Nå¤©æ¡ä»¶
        if 'continuous_' in operator:
            op = operator.replace('continuous_', '')
            
            # æ·»åŠ è¿ç»­å¤©æ•°çš„æ•°æ®åˆ°å±•ç¤ºåˆ—
            for day in range(1, days + 1):
                detail_columns.append(f"day{i}_{day}.`{field}` AS `{field}_day{day}`")
            
            # ä¸ºæ¯ä¸€å¤©åˆ›å»ºJOINï¼Œç‰¹æ®Šå¤„ç†sector_trendè¡¨
            for day in range(1, days + 1):
                if table == "sector_trend":
                    detail_joins.append(f"""
                    LEFT JOIN (
                        SELECT 
                            `åç§°` as code_match, 
                            `{field}`
                        FROM (
                            SELECT 
                                `åç§°`, 
                                `{field}`,
                                ROW_NUMBER() OVER(PARTITION BY `åç§°` ORDER BY `æ•°æ®æ—¥æœŸ` DESC) as row_num
                            FROM `{table}`
                        ) ranked
                        WHERE row_num = {day}
                    ) day{i}_{day} ON cf.`åç§°` = day{i}_{day}.code_match
                    """)
                else:
                    detail_joins.append(f"""
                    LEFT JOIN (
                        SELECT 
                            `ä»£ç ` as code_match, 
                            `{field}`
                        FROM (
                            SELECT 
                                `ä»£ç `, 
                                `{field}`,
                                ROW_NUMBER() OVER(PARTITION BY `ä»£ç ` ORDER BY `æ•°æ®æ—¥æœŸ` DESC) as row_num
                            FROM `{table}`
                        ) ranked
                        WHERE row_num = {day}
                    ) day{i}_{day} ON cf.`ä»£ç ` = day{i}_{day}.code_match
                    """)
            
            # ä½¿ç”¨çª—å£å‡½æ•°æ‰¾å‡ºè¿ç»­æ»¡è¶³æ¡ä»¶çš„è®°å½•
            if table == "sector_trend":
                sub_query = f"""
                SELECT t1.`åç§°` as matching_code
                FROM (
                    SELECT 
                        `åç§°`,
                        `æ•°æ®æ—¥æœŸ`,
                        `{field}`,
                        ROW_NUMBER() OVER(PARTITION BY `åç§°` ORDER BY `æ•°æ®æ—¥æœŸ` DESC) as date_rank
                    FROM `{table}`
                ) as t1
                WHERE t1.date_rank <= {days}
                AND t1.`{field}` {op} {value}
                GROUP BY t1.`åç§°`
                HAVING COUNT(t1.`åç§°`) = {days}
                """
            else:
                sub_query = f"""
                SELECT t1.`ä»£ç ` as matching_code
                FROM (
                    SELECT 
                        `ä»£ç `,
                        `æ•°æ®æ—¥æœŸ`,
                        `{field}`,
                        ROW_NUMBER() OVER(PARTITION BY `ä»£ç ` ORDER BY `æ•°æ®æ—¥æœŸ` DESC) as date_rank
                    FROM `{table}`
                ) as t1
                WHERE t1.date_rank <= {days}
                AND t1.`{field}` {op} {value}
                GROUP BY t1.`ä»£ç `
                HAVING COUNT(t1.`ä»£ç `) = {days}
                """
            sub_queries.append((sub_query, table))
            
        elif 'avg_' in operator:
            # å‡å€¼æ¡ä»¶å¤„ç†... (çœç•¥)
            pass
            
        else:
            # æ™®é€šæ¡ä»¶ - æ·»åŠ æœ€æ–°å€¼åˆ°æ˜ç»†å±•ç¤º
            detail_columns.append(f"latest{i}.`{field}` AS `{field}_latest`")
            
            # åˆ›å»ºJOINè·å–æœ€æ–°å€¼ï¼Œç‰¹æ®Šå¤„ç†sector_trendè¡¨
            if table == "sector_trend":
                detail_joins.append(f"""
                LEFT JOIN (
                    SELECT 
                        `åç§°` as code_match, 
                        `{field}`
                    FROM `{table}`
                    WHERE `æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `{table}`)
                ) latest{i} ON cf.`åç§°` = latest{i}.code_match
                """)
                
                # æ™®é€šæ¡ä»¶æŸ¥è¯¢
                sub_query = f"""
                SELECT `åç§°` as matching_code
                FROM `{table}`
                WHERE `æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `{table}`)
                AND `{field}` {operator} {value}
                """
            else:
                detail_joins.append(f"""
                LEFT JOIN (
                    SELECT 
                        `ä»£ç ` as code_match, 
                        `{field}`
                    FROM `{table}`
                    WHERE `æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `{table}`)
                ) latest{i} ON cf.`ä»£ç ` = latest{i}.code_match
                """)
                
                # æ™®é€šæ¡ä»¶æŸ¥è¯¢
                sub_query = f"""
                SELECT `ä»£ç ` as matching_code
                FROM `{table}`
                WHERE `æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `{table}`)
                AND `{field}` {operator} {value}
                """
            sub_queries.append((sub_query, table))
    
    # ç»„åˆæ‰€æœ‰å­æŸ¥è¯¢ï¼ˆäº¤é›†ï¼‰
    if not sub_queries:
        return None, []
    
    # é¢„å¤„ç†å­æŸ¥è¯¢ï¼Œå¤„ç†sector_trendè¡¨çš„ç‰¹æ®Šæƒ…å†µ
    processed_queries = []
    
    for query, table in sub_queries:
        if table == "sector_trend":
            # å¯¹äºsector_trendè¡¨ï¼Œéœ€è¦ä½¿ç”¨åç§°è¿›è¡ŒåŒ¹é…
            processed_query = f"""
            SELECT cf.`ä»£ç ` as matching_code
            FROM `capital_flow` cf
            JOIN ({query}) st ON cf.`åç§°` = st.matching_code
            WHERE cf.`æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `capital_flow`)
            """
            processed_queries.append(processed_query)
        else:
            processed_queries.append(query)
    
    # MySQL 5.xä¸æ”¯æŒINTERSECTï¼Œä½¿ç”¨JOINæˆ–WITHå­å¥ä»£æ›¿
    if len(processed_queries) == 1:
        combined_query = processed_queries[0]
    else:
        # ä½¿ç”¨WITHå­å¥å®ç°äº¤é›†
        combined_query = f"""
        WITH query1 AS ({processed_queries[0]})
        """
        for i, query in enumerate(processed_queries[1:], 1):
            combined_query += f"""
            , query{i+1} AS ({query})
            """
        
        combined_query += """
        SELECT q1.matching_code
        FROM query1 q1
        """
        
        for i in range(1, len(processed_queries)):
            combined_query += f"""
            JOIN query{i+1} q{i+1} ON q1.matching_code = q{i+1}.matching_code
            """
    
    # æ„å»ºæœ€ç»ˆæŸ¥è¯¢ - åŠ¨æ€æ·»åŠ è¯¦ç»†ä¿¡æ¯åˆ—
    detail_columns_str = ""
    if detail_columns:
        detail_columns_str = ", " + ", ".join(detail_columns)
    
    # æ‹¼æ¥JOINè¯­å¥
    detail_joins_str = " ".join(detail_joins)
    
    # æ„å»ºæ¿å—ç±»å‹è¿‡æ»¤æ¡ä»¶
    board_type_filter = ""
    if board_type:
        board_type_filter = f" AND bkt.`board_type` = '{board_type}'"
    
    final_query = f"""
    SELECT 
        cf.`ä»£ç ` as ts_code,
        cf.`åç§°` as name,
        COALESCE(bkt.`board_type`, 'æœªçŸ¥') as æ¿å—ç±»å‹,
        cf.`ä¸»åŠ›å‡€æµå…¥`,
        cf.`è¶…å¤§å•å‡€é¢` as è¶…å¤§å•å‡€æµå…¥,
        cf.`å¤§å•å‡€é¢` as å¤§å•å‡€æµå…¥,
        cf.`ä¸­å•å‡€é¢` as ä¸­å•å‡€æµå…¥,
        cf.`å°å•å‡€é¢` as å°å•å‡€æµå…¥,
        dde.`DDX` as dde_value,
        pos.`ä»Šæ—¥å¢ä»“å æ¯”` as position_value,
        cf.`æ•°æ®æ—¥æœŸ` as flow_date{detail_columns_str}
    FROM `capital_flow` cf
    LEFT JOIN `dde_analysis` dde ON cf.`ä»£ç ` = dde.`ä»£ç ` 
      AND dde.`æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `dde_analysis`)
    LEFT JOIN `position_analysis` pos ON cf.`ä»£ç ` = pos.`ä»£ç ` 
      AND pos.`æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `position_analysis`)
    LEFT JOIN `bk_type_mapping` bkt ON cf.`ä»£ç ` = bkt.`bk_code`
    {detail_joins_str}
    WHERE cf.`æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `capital_flow`)
    AND cf.`ä»£ç ` IN ({combined_query}){board_type_filter}
    """
    
    return final_query, detail_columns

def execute_query(query):
    """æ‰§è¡ŒSQLæŸ¥è¯¢"""
    if not query:
        st.error("æ²¡æœ‰æœ‰æ•ˆçš„æŸ¥è¯¢æ¡ä»¶")
        return pd.DataFrame()
    
    try:
        # å°†SQLæŸ¥è¯¢æ”¾åœ¨å¯å±•å¼€åŒºåŸŸï¼Œé»˜è®¤éšè—
        with st.expander("ğŸ” æŸ¥çœ‹æ‰§è¡Œçš„SQLæŸ¥è¯¢", expanded=False):
            st.code(query, language="sql")
        
        # æ‰§è¡Œå®Œæ•´æŸ¥è¯¢
        results_df = db.query_to_dataframe(query)
        st.write(f"æŸ¥è¯¢æˆåŠŸï¼Œè·å–åˆ° {len(results_df)} æ¡è®°å½•")
        return results_df
        
    except Exception as e:
        st.error("æŸ¥è¯¢æ‰§è¡Œå‡ºé”™")
        with st.expander("ğŸ” æŸ¥çœ‹é”™è¯¯è¯¦æƒ…", expanded=True):
            st.exception(e)
            
            # ä¿ç•™ç®€åŒ–æŸ¥è¯¢ä»¥ä¾¿è¯Šæ–­é—®é¢˜
            try:
                st.subheader("å°è¯•æ‰§è¡Œç®€åŒ–æŸ¥è¯¢...")
                simple_query = """
                SELECT COUNT(*) as total 
                FROM `capital_flow` 
                WHERE `æ•°æ®æ—¥æœŸ` = (SELECT MAX(`æ•°æ®æ—¥æœŸ`) FROM `capital_flow`)
                """
                st.code(simple_query, language="sql")
                test_df = db.query_to_dataframe(simple_query)
                st.write(f"ç®€åŒ–æŸ¥è¯¢æˆåŠŸï¼Œå…±æœ‰ {test_df.iloc[0]['total']} æ¡è®°å½•")
                
                # æ£€æŸ¥MySQLç‰ˆæœ¬
                st.subheader("æ£€æŸ¥MySQLç‰ˆæœ¬å…¼å®¹æ€§...")
                version_query = """
                SELECT VERSION() as mysql_version
                """
                version_df = db.query_to_dataframe(version_query)
                if not version_df.empty:
                    st.write(f"MySQLç‰ˆæœ¬: {version_df.iloc[0]['mysql_version']}")
            except Exception as test_e:
                st.error(f"ç®€åŒ–æŸ¥è¯¢ä¹Ÿå¤±è´¥: {str(test_e)}")
        
        return pd.DataFrame()

def main():
    """ä¸»å‡½æ•°"""
    # æ·»åŠ å…¨å±€æ¿å—ç±»å‹è¿‡æ»¤
    with st.expander("ğŸ” å…¨å±€æ¿å—ç±»å‹è¿‡æ»¤", expanded=True):
        board_type_options = {
            "å…¨éƒ¨æ¿å—": None,
            "æ¦‚å¿µæ¿å—": "æ¦‚å¿µ", 
            "è¡Œä¸šæ¿å—": "è¡Œä¸š", 
            "åœ°åŒºæ¿å—": "åœ°åŒº", 
            "é£æ ¼æ¿å—": "é£æ ¼"
        }
        
        selected_board_type_display = st.selectbox(
            "é€‰æ‹©è¦æ˜¾ç¤ºçš„æ¿å—ç±»å‹", 
            list(board_type_options.keys()),
            index=0,  # é»˜è®¤é€‰æ‹©"å…¨éƒ¨æ¿å—"
            key="global_board_type_filter"  # æ·»åŠ å”¯ä¸€çš„key
        )
        selected_board_type = board_type_options[selected_board_type_display]
        
        if selected_board_type:
            st.success(f"å·²è®¾ç½®å…¨å±€è¿‡æ»¤: åªæ˜¾ç¤º{selected_board_type_display}ç»“æœ")
        else:
            st.info("å½“å‰æ˜¾ç¤ºæ‰€æœ‰ç±»å‹çš„æ¿å—")
    
    # ç­›é€‰åŒºæ•°é‡è®¾ç½®
    col1, col2 = st.columns([0.3, 0.7])
    with col1:
        st.write("ğŸ“Š ç­›é€‰åŒºæ•°é‡")
    with col2:
        num_areas = st.number_input(
            "",
            min_value=1,
            max_value=5,
            value=1,
            key="num_filter_areas",
            label_visibility="collapsed"
        )
    
    # åˆ›å»ºå¤šä¸ªç­›é€‰åŒº
    for area_idx in range(num_areas):
        area_name = chr(65 + area_idx)  # A, B, C...
        create_filter_area(area_name)
    
    # ç»Ÿä¸€æ‰§è¡ŒæŒ‰é’®
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        execute_button = st.button("æ‰§è¡Œå…¨éƒ¨ç­›é€‰", type="primary", use_container_width=True)
    
    if execute_button:
        if 'filter_conditions' in st.session_state:
            # æ¸…ç©ºä¹‹å‰çš„ç­›é€‰ç»“æœ
            if 'filter_results' not in st.session_state:
                st.session_state.filter_results = {}
            else:
                st.session_state.filter_results.clear()
            
            # åœ¨æŒ‰é’®ä¸‹æ–¹æ˜¾ç¤ºç»“æœåŒºåŸŸ
            st.markdown("## ç­›é€‰ç»“æœ")
            
            # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„è¿‡æ»¤æ¡ä»¶
            if selected_board_type:
                st.info(f"å…¨å±€æ¿å—ç±»å‹è¿‡æ»¤: åªæ˜¾ç¤º{selected_board_type_display}")
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_bar = st.progress(0)
            progress_text = st.empty()
            
            # è·å–å½“å‰æ˜¾ç¤ºçš„ç­›é€‰åŒº
            active_areas = [chr(65 + i) for i in range(num_areas)]
            total_areas = len([name for name in st.session_state.filter_conditions.keys() if name in active_areas])
            
            for i, area_name in enumerate([name for name in st.session_state.filter_conditions.keys() if name in active_areas]):
                # æ›´æ–°è¿›åº¦
                progress = int((i / total_areas) * 100)
                progress_bar.progress(progress)
                progress_text.text(f"å¤„ç†ç­›é€‰åŒº {area_name} ({i+1}/{total_areas})...")
                
                # åˆ›å»ºç»“æœå®¹å™¨
                result_container = st.container()
                with result_container:
                    st.markdown(f"### ç­›é€‰åŒº {area_name} ç»“æœ")
                    
                    conditions = st.session_state.filter_conditions[area_name]
                    # æ²¡æœ‰æ¡ä»¶æ—¶è·³è¿‡
                    if not conditions:
                        st.warning("æ²¡æœ‰è®¾ç½®ç­›é€‰æ¡ä»¶")
                        continue
                    
                    try:
                        # æ„å»ºå¹¶æ‰§è¡ŒæŸ¥è¯¢
                        query, detail_columns = build_stock_query(conditions, selected_board_type)
                        results_df = execute_query(query)
                        
                        # æ˜¾ç¤ºç»“æœ
                        if not results_df.empty:
                            # ä½¿ç”¨åˆ—å¸ƒå±€æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ - ç®€åŒ–ä¸ºåªæ˜¾ç¤ºè‚¡ç¥¨æ•°é‡
                            st.success(f"æ‰¾åˆ° {len(results_df)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
                            
                            # æ˜¾ç¤ºæ¿å—ç±»å‹ç»Ÿè®¡ä¿¡æ¯
                            if 'æ¿å—ç±»å‹' in results_df.columns:
                                board_type_counts = results_df['æ¿å—ç±»å‹'].value_counts()
                                if not board_type_counts.empty:
                                    with st.expander("æ¿å—ç±»å‹åˆ†å¸ƒ", expanded=False):
                                        for btype, count in board_type_counts.items():
                                            st.write(f"{btype}: {count}åª")
                            
                            # ä¿å­˜ç»“æœä»¥ä¾¿ç¨ååˆ†æ
                            st.session_state.filter_results[area_name] = results_df
                            
                            # æ ¼å¼åŒ–æ•°å€¼åˆ—
                            display_df = results_df.copy()
                            
                            # æ ‡è¯†é‡è¦çš„å±•ç¤ºåˆ—
                            special_columns = []
                            for condition in conditions:
                                field = condition['field']
                                operator = condition['operator']
                                days = condition['days']
                                
                                # å¯¹äºè¿ç»­å¤©æ•°æ¡ä»¶ï¼Œæ ‡è®°ç›¸å…³åˆ—ä»¥çªå‡ºæ˜¾ç¤º
                                if 'continuous_' in operator:
                                    for day in range(1, days + 1):
                                        col_name = f"{field}_day{day}"
                                        if col_name in display_df.columns:
                                            special_columns.append(col_name)
                                # å¯¹äºæ™®é€šæ¡ä»¶ï¼Œæ ‡è®°æœ€æ–°å€¼åˆ—
                                else:
                                    col_name = f"{field}_latest"
                                    if col_name in display_df.columns:
                                        special_columns.append(col_name)
                            
                            # è®¾ç½®æ•°å­—æ ¼å¼
                            numeric_cols = display_df.select_dtypes(include=['float64', 'int64']).columns
                            format_dict = {}
                            for col in numeric_cols:
                                if 'å‡€æµå…¥' in col or 'å‡€é¢' in col or '_day' in col or '_latest' in col:
                                    format_dict[col] = '{:,.2f}'
                                elif '_ratio' in col:
                                    format_dict[col] = '{:.2f}'
                            
                            # ç§»é™¤ä¸»è¡¨æ ¼ï¼Œåªä¿ç•™è¯¦æƒ…è¡¨
                            if special_columns and len(special_columns) > 0:
                                # åˆ›å»ºåªåŒ…å«å¿…è¦åˆ—çš„è¯¦æƒ…è§†å›¾
                                detail_view = display_df[['ts_code', 'name', 'æ¿å—ç±»å‹'] + special_columns].copy()
                                # ç›´æ¥æ˜¾ç¤ºè¯¦æƒ…è§†å›¾ä½œä¸ºä¸»è¡¨æ ¼
                                st.dataframe(detail_view.style.format(format_dict), use_container_width=True)
                            else:
                                # å¦‚æœæ²¡æœ‰ç‰¹æ®Šåˆ—ï¼Œåˆ™æ˜¾ç¤ºåŸºæœ¬è¡¨æ ¼
                                basic_columns = ['ts_code', 'name', 'æ¿å—ç±»å‹', 'ä¸»åŠ›å‡€æµå…¥', 'flow_date']
                                basic_view = display_df[basic_columns].copy()
                                st.dataframe(basic_view.style.format(format_dict), use_container_width=True)
                        else:
                            st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
                    except Exception as e:
                        st.error(f"æŸ¥è¯¢å‡ºé”™: {str(e)}")
            
            # å®Œæˆæ‰€æœ‰æŸ¥è¯¢
            progress_bar.progress(100)
            progress_text.text("æ‰€æœ‰ç­›é€‰åŒºå¤„ç†å®Œæˆ!")
            
            # æŸ¥è¯¢å®Œæˆåæ˜¾ç¤ºå…±åŒè‚¡ç¥¨åˆ†æ - ä¿ç•™æ­¤åŠŸèƒ½
            if len(st.session_state.filter_results) > 1:
                st.markdown("### ğŸ” å…±åŒè‚¡ç¥¨åˆ†æ")
                
                # è·å–æ‰€æœ‰ç­›é€‰åŒºçš„è‚¡ç¥¨é›†åˆ
                stock_sets = {name: set(df['ts_code']) for name, df in st.session_state.filter_results.items()}
                
                # è®¡ç®—äº¤é›†
                intersection = set.intersection(*stock_sets.values())
                if intersection:
                    # åˆ›å»ºå…±åŒè‚¡ç¥¨çš„è¯¦ç»†ä¿¡æ¯DataFrame
                    common_stocks = pd.DataFrame({
                        'è‚¡ç¥¨ä»£ç ': list(intersection),
                        'è‚¡ç¥¨åç§°': [next(df[df['ts_code'] == code]['name'].iloc[0] 
                                    for df in st.session_state.filter_results.values() 
                                    if code in df['ts_code'].values) 
                                for code in intersection],
                        'æ¿å—ç±»å‹': [next(df[df['ts_code'] == code]['æ¿å—ç±»å‹'].iloc[0] 
                                   for df in st.session_state.filter_results.values() 
                                   if code in df['ts_code'].values) 
                               for code in intersection]
                    })
                    
                    # æ˜¾ç¤ºç»“æœç»Ÿè®¡ - ç®€åŒ–ä¸ºåªæ˜¾ç¤ºè‚¡ç¥¨æ•°é‡
                    st.success(f"å‘ç° {len(intersection)} åªåœ¨æ‰€æœ‰ç­›é€‰åŒºä¸­éƒ½å‡ºç°çš„è‚¡ç¥¨")
                    
                    # æ˜¾ç¤ºå…±åŒè‚¡ç¥¨è¡¨æ ¼
                    st.dataframe(common_stocks, use_container_width=True)
                    
                    # ä¿ç•™å¯¼å‡ºåŠŸèƒ½
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        common_stocks.to_excel(writer, sheet_name="å…±åŒè‚¡ç¥¨", index=False)
                        for name, df in st.session_state.filter_results.items():
                            df.to_excel(writer, sheet_name=f"ç­›é€‰åŒº{name}å®Œæ•´ç»“æœ", index=False)
                    
                    excel_data = output.getvalue()
                    st.download_button(
                        label="å¯¼å‡ºåˆ†æç»“æœ",
                        data=excel_data,
                        file_name=f"é€‰è‚¡åˆ†æç»“æœ_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.ms-excel"
                    )
                else:
                    st.info("æ²¡æœ‰åœ¨æ‰€æœ‰ç­›é€‰åŒºä¸­éƒ½å‡ºç°çš„è‚¡ç¥¨")
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### ä½¿ç”¨è¯´æ˜
        1. é€‰æ‹©éœ€è¦çš„ç­›é€‰åŒºæ•°é‡ï¼ˆ1-5ä¸ªï¼‰
        2. åœ¨æ¯ä¸ªç­›é€‰åŒºä¸­è®¾ç½®ç­›é€‰æ¡ä»¶
        3. ç‚¹å‡»åº•éƒ¨çš„"æ‰§è¡Œå…¨éƒ¨ç­›é€‰"æŒ‰é’®
        4. æŸ¥çœ‹å„ä¸ªç­›é€‰åŒºçš„ç»“æœå’Œå…±åŒè‚¡ç¥¨åˆ†æ
        
        #### æ¡ä»¶ç±»å‹è¯´æ˜ï¼š
        - **æ™®é€šæ¡ä»¶**ï¼ˆå¦‚ï¼šå¤§äºã€å°äºç­‰ï¼‰ï¼šæ¯”è¾ƒæœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®
        - **è¿ç»­nå¤©æ¡ä»¶**ï¼šä»æœ€æ–°äº¤æ˜“æ—¥èµ·å¾€å‰è¿ç»­nå¤©éƒ½æ»¡è¶³æ¡ä»¶
        - **å‡å€¼æ¡ä»¶**ï¼šå°†æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®ä¸næ—¥å‡å€¼è¿›è¡Œæ¯”è¾ƒ
        
        #### ç‰¹åˆ«è¯´æ˜ï¼š
        - æ‰€æœ‰æ¡ä»¶éƒ½åŸºäºæ•°æ®åº“æœ€æ–°äº¤æ˜“æ—¥çš„æ•°æ®è¿›è¡Œè®¡ç®—å’Œæ¯”è¾ƒ
        - å¯ä»¥å¯¼å‡ºç­›é€‰ç»“æœå’Œå…±åŒè‚¡ç¥¨åˆ†æ
        """)

if __name__ == "__main__":
    main() 

# æ·»åŠ å…¨å±€æ‚¬æµ®åŠ©æ‰‹
try:
    add_global_assistant()
except Exception as e:
    print(f"Error adding global assistant: {e}")