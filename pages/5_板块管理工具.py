import streamlit as st
# å¯¼å…¥å…¨å±€åŠ©æ‰‹
try:
    from backend.helper import add_global_assistant
except ImportError:
    print("Error importing assistant helper")
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
from datetime import datetime
import os
import traceback
from backend.db import db
from dotenv import load_dotenv
from pathlib import Path

# åŠ è½½ç¯å¢ƒå˜é‡
env_path = Path(__file__).parent.parent / "config" / ".env"
load_dotenv(env_path)

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå¸ƒå±€
st.set_page_config(page_title="æ¿å—ç®¡ç†å·¥å…·", layout="wide")
st.title("æ¿å—ç®¡ç†å·¥å…·")

# åˆ›å»ºä¸€ä¸ªè¿›åº¦å®¹å™¨æ¥æ˜¾ç¤ºæ“ä½œè¿›åº¦
progress_container = st.empty()

# è·å–å½“å‰è·Ÿè¸ªçš„æ¿å—åˆ—è¡¨
def get_tracked_sectors():
    try:
        st.write("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢...")
        query = """
            SELECT DISTINCT ä»£ç  as stock_code, åç§° as stock_name 
            FROM merged_data_specified 
            ORDER BY ä»£ç 
        """
        st.write(f"æ‰§è¡ŒSQLæŸ¥è¯¢: {query}")
        results_df = db.query_to_dataframe(query)
        st.write(f"æŸ¥è¯¢ç»“æœ: {len(results_df)} æ¡è®°å½•")
        
        return results_df
    except Exception as e:
        st.error(f"è·å–æ¿å—åˆ—è¡¨å¤±è´¥: {str(e)}")
        st.write(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
        st.write(traceback.format_exc())
        return pd.DataFrame(columns=['stock_code', 'stock_name'])

# å°†NumPyç±»å‹è½¬æ¢ä¸ºPythonæ ‡å‡†ç±»å‹
def convert_numpy_types(value):
    if isinstance(value, (np.integer, np.int64, np.int32, np.int16, np.int8)):
        return int(value)
    elif isinstance(value, (np.floating, np.float64, np.float32)):
        if np.isnan(value):  # æ˜ç¡®å¤„ç†NaNå€¼
            return None
        return float(value)
    elif isinstance(value, np.bool_):
        return bool(value)
    elif isinstance(value, np.datetime64):
        return pd.Timestamp(value).to_pydatetime()
    elif isinstance(value, np.ndarray):
        return value.tolist()
    elif pd.isna(value):
        return None
    elif isinstance(value, str) and value.strip() == '':  # å¤„ç†ç©ºå­—ç¬¦ä¸²
        return None
    return value

# å®‰å…¨åœ°ä»DataFrameè¡Œä¸­è·å–å€¼
def safe_get_value(row, column):
    """å®‰å…¨åœ°ä»DataFrameè¡Œä¸­è·å–å€¼ï¼Œå¤„ç†ä»»ä½•å¼‚å¸¸"""
    try:
        if column not in row.index:
            return None
        value = row[column]
        return convert_numpy_types(value)
    except Exception as e:
        # å‘ç”Ÿä»»ä½•é”™è¯¯ï¼Œè¿”å›Noneè€Œä¸æ˜¯å¤±è´¥
        return None

# æ·»åŠ æ–°æ¿å—åˆ°è·Ÿè¸ªæ± 
def add_sector_to_pool(sector_code, sector_name):
    progress_text = st.empty()
    progress_bar = st.progress(0, "å¤„ç†ä¸­")
    
    try:
        progress_text.write("æ­¥éª¤1/7: å¼€å§‹æ·»åŠ æ¿å—æµç¨‹...")
        progress_bar.progress(10, text="å¼€å§‹å¤„ç†")
        
        # è·å–èµ„é‡‘æµå‘å†å²æ•°æ®
        progress_text.write("æ­¥éª¤2/7: æ­£åœ¨æŸ¥è¯¢èµ„é‡‘æµå‘å†å²æ•°æ®...")
        progress_bar.progress(20, text="æŸ¥è¯¢èµ„é‡‘æµå‘æ•°æ®")
        
        capital_flow_query = f"""
            SELECT *
            FROM capital_flow
            WHERE ä»£ç  = '{sector_code}'
            ORDER BY æ•°æ®æ—¥æœŸ DESC
        """
        st.code(capital_flow_query, language="sql")
        
        try:
            capital_flow_data = db.query_to_dataframe(capital_flow_query)
            st.write(f"èµ„é‡‘æµå‘æ•°æ®æŸ¥è¯¢å®Œæˆï¼Œè·å–åˆ° {len(capital_flow_data)} æ¡è®°å½•")
            if not capital_flow_data.empty:
                st.write("èµ„é‡‘æµå‘æ•°æ®æ ·ä¾‹:")
                st.write(capital_flow_data.head(1))
            else:
                st.warning("æœªæ‰¾åˆ°èµ„é‡‘æµå‘æ•°æ®")
        except Exception as query_error:
            error_message = str(query_error).lower()
            
            # åˆ¤æ–­é”™è¯¯ç±»å‹ï¼Œæä¾›æ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
            if "timeout" in error_message or "connection" in error_message or "connect" in error_message:
                st.error(f"ğŸ“¶ æ•°æ®åº“è¿æ¥è¶…æ—¶æˆ–ç½‘ç»œé—®é¢˜: {str(query_error)}")
                st.info("ğŸ’¡ å»ºè®®: è¯·ç­‰å¾…å‡ ç§’é’Ÿåå†æ¬¡å°è¯•æ·»åŠ ï¼Œæˆ–è€…æ£€æŸ¥æ•°æ®åº“æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
            elif "access denied" in error_message or "permission" in error_message:
                st.error(f"ğŸ”’ æ•°æ®åº“è®¿é—®æƒé™é—®é¢˜: {str(query_error)}")
            elif "table" in error_message and ("not exist" in error_message or "doesn't exist" in error_message):
                st.error(f"ğŸ“‹ æ•°æ®è¡¨ä¸å­˜åœ¨: {str(query_error)}")
                st.info("ğŸ’¡ å»ºè®®: è¯·ç¡®è®¤æ•°æ®åº“ä¸­æ˜¯å¦å­˜åœ¨capital_flowè¡¨")
            else:
                st.error(f"âŒ æŸ¥è¯¢èµ„é‡‘æµå‘æ•°æ®æ—¶å‡ºé”™: {str(query_error)}")
            
            st.write(traceback.format_exc())
            progress_text.write("æ·»åŠ æ¿å—å¤±è´¥: æŸ¥è¯¢èµ„é‡‘æµå‘æ•°æ®é”™è¯¯")
            progress_bar.progress(100, text="æ“ä½œå¤±è´¥")
            return
        
        if capital_flow_data.empty:
            # æä¾›æ›´æ˜ç¡®çš„æ•°æ®ä¸å­˜åœ¨æç¤º
            progress_text.write("æ·»åŠ æ¿å—å¤±è´¥: æ‰¾ä¸åˆ°èµ„é‡‘æµå‘æ•°æ®")
            progress_bar.progress(100, text="æ“ä½œå¤±è´¥")
            
            # æ£€æŸ¥èµ„é‡‘æµè¡¨ä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•è®°å½•ï¼Œæ¥åˆ¤æ–­æ˜¯å¦æ˜¯è¡¨ç»“æ„é—®é¢˜
            try:
                check_table_query = "SELECT COUNT(*) as count FROM capital_flow LIMIT 1"
                table_check = db.query_to_dataframe(check_table_query)
                total_records = table_check.iloc[0]['count'] if not table_check.empty else 0
                
                if total_records == 0:
                    st.error(f"â— èµ„é‡‘æµå‘è¡¨ä¸ºç©º: capital_flowè¡¨ä¸­æ²¡æœ‰ä»»ä½•è®°å½•")
                    st.info("ğŸ’¡ å»ºè®®: è¯·å…ˆå¯¼å…¥èµ„é‡‘æµå‘æ•°æ®")
                else:
                    # æ£€æŸ¥å…¶ä»–æ¿å—æ˜¯å¦æœ‰æ•°æ®ï¼Œåˆ¤æ–­æ˜¯å¦æ˜¯ç‰¹å®šæ¿å—çš„é—®é¢˜
                    other_records_query = "SELECT DISTINCT ä»£ç  FROM capital_flow LIMIT 5"
                    other_records = db.query_to_dataframe(other_records_query)
                    
                    if not other_records.empty:
                        available_sectors = ", ".join(other_records['ä»£ç '].tolist())
                        st.error(f"âŒ æ¿å— {sector_code} '{sector_name}' åœ¨èµ„é‡‘æµå‘è¡¨ä¸­æ²¡æœ‰æ•°æ®")
                        st.info(f"ğŸ’¡ å»ºè®®: è¯·ç¡®è®¤æ¿å—ä»£ç æ˜¯å¦æ­£ç¡®ã€‚èµ„é‡‘æµå‘è¡¨ä¸­ç°æœ‰çš„æ¿å—ä»£ç ç¤ºä¾‹: {available_sectors}")
                    else:
                        st.error(f"â“ èµ„é‡‘æµå‘è¡¨ç»“æ„å¯èƒ½æœ‰é—®é¢˜")
            except Exception as check_error:
                st.error(f"ğŸ” æ— æ³•æ£€æŸ¥èµ„é‡‘æµå‘è¡¨çŠ¶æ€: {str(check_error)}")
            
            return
        
        # è·å–å·²æœ‰æ•°æ®çš„æ—¥æœŸåˆ—è¡¨ï¼Œç”¨äºåç»­è¿‡æ»¤
        progress_text.write("æ­¥éª¤3/7: è·å–å·²å­˜åœ¨çš„æ•°æ®æ—¥æœŸ...")
        progress_bar.progress(30, text="æ£€æŸ¥å·²æœ‰æ•°æ®")
        
        existing_dates_query = f"""
            SELECT æ•°æ®æ—¥æœŸ
            FROM merged_data_specified
            WHERE ä»£ç  = '{sector_code}'
        """
        
        try:
            existing_dates_df = db.query_to_dataframe(existing_dates_query)
            existing_dates = set()
            if not existing_dates_df.empty:
                existing_dates = set(pd.to_datetime(existing_dates_df['æ•°æ®æ—¥æœŸ']).dt.strftime('%Y-%m-%d'))
            
            st.write(f"å·²æœ‰ {len(existing_dates)} ä¸ªæ—¥æœŸçš„æ•°æ®")
        except Exception as check_error:
            error_message = str(check_error).lower()
            
            # åˆ¤æ–­é”™è¯¯ç±»å‹
            if "timeout" in error_message or "connection" in error_message:
                st.error(f"ğŸ“¶ æ•°æ®åº“è¿æ¥è¶…æ—¶æˆ–ç½‘ç»œé—®é¢˜: {str(check_error)}")
            elif "access denied" in error_message or "permission" in error_message:
                st.error(f"ğŸ”’ æ•°æ®åº“è®¿é—®æƒé™é—®é¢˜: {str(check_error)}")
            elif "table" in error_message and ("not exist" in error_message or "doesn't exist" in error_message):
                st.error(f"ğŸ“‹ merged_data_specifiedè¡¨ä¸å­˜åœ¨: {str(check_error)}")
                st.info("ğŸ’¡ è¡¨å¯èƒ½å°šæœªåˆ›å»ºï¼Œå°†æ­£å¸¸ç»§ç»­å¤„ç†")
            else:
                st.error(f"âŒ æ£€æŸ¥å·²æœ‰æ•°æ®æ—¶å‡ºé”™: {str(check_error)}")
            
            st.write(traceback.format_exc())
            existing_dates = set()  # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œå‡è®¾æ²¡æœ‰ç°æœ‰æ•°æ®
        
        # å‡†å¤‡æŸ¥è¯¢å…¶ä»–è¡¨çš„æ•°æ®
        progress_text.write("æ­¥éª¤4/7: å‡†å¤‡å¤„ç†æ‰€æœ‰æ—¥æœŸæ•°æ®...")
        progress_bar.progress(40, text="å‡†å¤‡æ‰¹é‡å¤„ç†")
        
        # è·å–æ‰€æœ‰è¦å¤„ç†çš„æ—¥æœŸ
        all_dates = pd.to_datetime(capital_flow_data['æ•°æ®æ—¥æœŸ']).dt.strftime('%Y-%m-%d').unique()
        dates_to_process = [d for d in all_dates if d not in existing_dates]
        
        st.write(f"æ‰¾åˆ° {len(all_dates)} ä¸ªæ—¥æœŸçš„æ•°æ®ï¼Œéœ€è¦å¤„ç† {len(dates_to_process)} ä¸ªæ–°æ—¥æœŸ")
        
        if not dates_to_process:
            progress_text.write("æ·»åŠ æ¿å—å®Œæˆ: æ²¡æœ‰æ–°çš„æ•°æ®éœ€è¦æ·»åŠ ")
            progress_bar.progress(100, text="æ— éœ€æ“ä½œ")
            st.success(f"æ¿å— {sector_code} {sector_name} çš„æ‰€æœ‰æ•°æ®å·²ç»å­˜åœ¨ï¼Œæ— éœ€æ·»åŠ ")
            return
        
        # æ”¶é›†æ‰€æœ‰æ—¥æœŸçš„DDEåˆ†æã€æŒä»“åˆ†æå’Œæ¿å—è¶‹åŠ¿æ•°æ®
        progress_text.write("æ­¥éª¤5/7: æ”¶é›†å…¶ä»–è¡¨çš„æ•°æ®...")
        progress_bar.progress(50, text="æ”¶é›†å…³è”æ•°æ®")
        
        # è·å–DDEåˆ†ææ•°æ®
        try:
            st.write("æ­£åœ¨æŸ¥è¯¢DDEåˆ†ææ•°æ®...")
            dde_query = f"""
                SELECT *
                FROM dde_analysis
                WHERE ä»£ç  = '{sector_code}'
            """
            dde_data = db.query_to_dataframe(dde_query)
            dde_data['æ•°æ®æ—¥æœŸ'] = pd.to_datetime(dde_data['æ•°æ®æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
            dde_data_dict = {row['æ•°æ®æ—¥æœŸ']: row for _, row in dde_data.iterrows()}
            st.write(f"DDEåˆ†ææ•°æ®è·å–: {'æˆåŠŸï¼Œè·å– ' + str(len(dde_data)) + ' æ¡è®°å½•' if not dde_data.empty else 'æ— æ•°æ®'}")
        except Exception as dde_error:
            error_message = str(dde_error).lower()
            
            if "timeout" in error_message or "connection" in error_message:
                st.warning(f"ğŸ“¶ DDEåˆ†ææ•°æ®æŸ¥è¯¢è¶…æ—¶æˆ–ç½‘ç»œé—®é¢˜: {str(dde_error)}")
                st.info("å°†ç»§ç»­å¤„ç†ï¼Œä½†å¯èƒ½ç¼ºå°‘DDEåˆ†ææ•°æ®")
            elif "table" in error_message and ("not exist" in error_message or "doesn't exist" in error_message):
                st.warning(f"ğŸ“‹ DDEåˆ†ææ•°æ®è¡¨ä¸å­˜åœ¨: {str(dde_error)}")
                st.info("å°†ç»§ç»­å¤„ç†ï¼Œä½†æ²¡æœ‰DDEåˆ†ææ•°æ®")
            else:
                st.warning(f"âš ï¸ æŸ¥è¯¢DDEåˆ†ææ•°æ®æ—¶å‡ºé”™: {str(dde_error)}")
            
            # è®°å½•è¯¦ç»†é”™è¯¯ï¼Œä½†ä¸ä¸­æ–­å¤„ç†
            with st.expander("æŸ¥çœ‹DDEåˆ†ææ•°æ®é”™è¯¯è¯¦æƒ…"):
                st.code(traceback.format_exc())
                
            dde_data_dict = {}
        
        # è·å–æŒä»“åˆ†ææ•°æ®
        try:
            st.write("æ­£åœ¨æŸ¥è¯¢æŒä»“åˆ†ææ•°æ®...")
            position_query = f"""
                SELECT *
                FROM position_analysis
                WHERE ä»£ç  = '{sector_code}'
            """
            position_data = db.query_to_dataframe(position_query)
            position_data['æ•°æ®æ—¥æœŸ'] = pd.to_datetime(position_data['æ•°æ®æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
            position_data_dict = {row['æ•°æ®æ—¥æœŸ']: row for _, row in position_data.iterrows()}
            st.write(f"æŒä»“åˆ†ææ•°æ®è·å–: {'æˆåŠŸï¼Œè·å– ' + str(len(position_data)) + ' æ¡è®°å½•' if not position_data.empty else 'æ— æ•°æ®'}")
        except Exception as position_error:
            error_message = str(position_error).lower()
            
            if "timeout" in error_message or "connection" in error_message:
                st.warning(f"ğŸ“¶ æŒä»“åˆ†ææ•°æ®æŸ¥è¯¢è¶…æ—¶æˆ–ç½‘ç»œé—®é¢˜: {str(position_error)}")
                st.info("å°†ç»§ç»­å¤„ç†ï¼Œä½†å¯èƒ½ç¼ºå°‘æŒä»“åˆ†ææ•°æ®")
            elif "table" in error_message and ("not exist" in error_message or "doesn't exist" in error_message):
                st.warning(f"ğŸ“‹ æŒä»“åˆ†ææ•°æ®è¡¨ä¸å­˜åœ¨: {str(position_error)}")
                st.info("å°†ç»§ç»­å¤„ç†ï¼Œä½†æ²¡æœ‰æŒä»“åˆ†ææ•°æ®")
            else:
                st.warning(f"âš ï¸ æŸ¥è¯¢æŒä»“åˆ†ææ•°æ®æ—¶å‡ºé”™: {str(position_error)}")
            
            # è®°å½•è¯¦ç»†é”™è¯¯ï¼Œä½†ä¸ä¸­æ–­å¤„ç†
            with st.expander("æŸ¥çœ‹æŒä»“åˆ†ææ•°æ®é”™è¯¯è¯¦æƒ…"):
                st.code(traceback.format_exc())
                
            position_data_dict = {}
        
        # è·å–æ¿å—è¶‹åŠ¿æ•°æ®
        try:
            st.write("æ­£åœ¨æŸ¥è¯¢æ¿å—è¶‹åŠ¿æ•°æ®...")
            # ç»Ÿä¸€æ¸…æ´—åç§°ï¼šå»é™¤ç©ºæ ¼å¹¶è½¬æ¢ä¸ºå¤§å†™
            sector_name_upper = sector_name.strip().upper()
            
            st.write(f"å¤„ç†åçš„æ¿å—åç§°: '{sector_name_upper}'")
            
            # å…ˆå°è¯•ç¡®åˆ‡åŒ¹é…ï¼Œä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢é¿å…SQLæ³¨å…¥å’Œè½¬ä¹‰é—®é¢˜
            exact_query = "SELECT * FROM sector_trend WHERE UPPER(TRIM(åç§°)) = %s"
            st.code(f"æ‰§è¡Œç²¾ç¡®åŒ¹é…æŸ¥è¯¢: {exact_query} [å‚æ•°: {sector_name_upper}]", language="sql")
            
            try:
                # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢è€Œä¸æ˜¯å­—ç¬¦ä¸²æ‹¼æ¥
                trend_data = db.query_to_dataframe(exact_query, params=[sector_name_upper])
                st.write(f"ç²¾ç¡®æŸ¥è¯¢ç»“æœ: {len(trend_data)} æ¡è®°å½•")
            except Exception as exact_query_error:
                st.warning(f"ç²¾ç¡®åŒ¹é…æŸ¥è¯¢å‡ºé”™: {str(exact_query_error)}")
                # å¦‚æœå‚æ•°åŒ–æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•ç›´æ¥æ‰§è¡ŒSQL
                fallback_exact_query = f"""
                    SELECT * 
                    FROM sector_trend 
                    WHERE UPPER(TRIM(åç§°)) = '{sector_name_upper.replace("'", "''")}'
                """
                st.code(f"å°è¯•å¤‡ç”¨æŸ¥è¯¢: {fallback_exact_query}", language="sql")
                trend_data = db.query_to_dataframe(fallback_exact_query)
                st.write(f"å¤‡ç”¨ç²¾ç¡®æŸ¥è¯¢ç»“æœ: {len(trend_data)} æ¡è®°å½•")
            
            # å¦‚æœç¡®åˆ‡åŒ¹é…æ²¡æœ‰ç»“æœï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
            if trend_data.empty:
                st.write(f"è­¦å‘Š: æœªèƒ½åœ¨ sector_trend è¡¨ä¸­æ‰¾åˆ°ä»»ä½•ç²¾ç¡®åŒ¹é…çš„æ¿å—åç§°")
                
                # è·å–è¡¨ä¸­æ‰€æœ‰æ¿å—åç§°ä½œä¸ºå‚è€ƒ
                try:
                    all_sectors_query = "SELECT DISTINCT åç§° FROM sector_trend LIMIT 100"
                    all_sectors = db.query_to_dataframe(all_sectors_query)
                    st.write(f"æ•°æ®åº“ä¸­çš„æ¿å—åç§°ç¤ºä¾‹: {all_sectors['åç§°'].tolist()[:10]}")
                except Exception as list_error:
                    st.warning(f"è·å–æ¿å—åˆ—è¡¨å‡ºé”™: {str(list_error)}")
                
                # è·å–å¯èƒ½çš„åç§°åŒ¹é…éƒ¨åˆ†
                base_name = sector_name_upper.replace('æ¦‚å¿µ', '').replace('æ¿å—', '').strip()
                st.write(f"ç”¨äºæ¨¡ç³ŠåŒ¹é…çš„åŸºç¡€åç§°: '{base_name}'")
                
                try:
                    # å°è¯•å‚æ•°åŒ–æ¨¡ç³ŠåŒ¹é…
                    fuzzy_query = "SELECT * FROM sector_trend WHERE UPPER(TRIM(åç§°)) LIKE %s"
                    fuzzy_param = f"%{base_name}%"
                    st.code(f"æ‰§è¡Œæ¨¡ç³ŠåŒ¹é…æŸ¥è¯¢: {fuzzy_query} [å‚æ•°: {fuzzy_param}]", language="sql")
                    trend_data = db.query_to_dataframe(fuzzy_query, params=[fuzzy_param])
                    st.write(f"æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ° {len(trend_data)} æ¡è®°å½•")
                except Exception as fuzzy_query_error:
                    st.warning(f"æ¨¡ç³ŠåŒ¹é…æŸ¥è¯¢å‡ºé”™: {str(fuzzy_query_error)}")
                    # å¦‚æœå‚æ•°åŒ–æŸ¥è¯¢å¤±è´¥ï¼Œå°è¯•ç›´æ¥æ‰§è¡ŒSQL
                    fallback_fuzzy_query = f"""
                        SELECT * 
                        FROM sector_trend 
                        WHERE UPPER(TRIM(åç§°)) LIKE '%{base_name.replace("'", "''")}%'
                    """
                    st.code(f"å°è¯•å¤‡ç”¨æ¨¡ç³ŠæŸ¥è¯¢: {fallback_fuzzy_query}", language="sql")
                    trend_data = db.query_to_dataframe(fallback_fuzzy_query)
                    st.write(f"å¤‡ç”¨æ¨¡ç³ŠæŸ¥è¯¢ç»“æœ: {len(trend_data)} æ¡è®°å½•")
                
                if not trend_data.empty:
                    # æ‰“å°åŒ¹é…åˆ°çš„åç§°
                    matched_names = trend_data['åç§°'].unique().tolist()
                    st.write(f"æ¨¡ç³ŠåŒ¹é…åˆ°çš„æ¿å—åç§°: {matched_names}")
            
            # å¤„ç†æŸ¥è¯¢ç»“æœ
            if not trend_data.empty:
                # å¦‚æœæ‰¾åˆ°å¤šä¸ªåŒ¹é…è®°å½•ï¼ŒæŒ‰æ—¥æœŸåˆ†ç»„
                trend_data['æ•°æ®æ—¥æœŸ'] = pd.to_datetime(trend_data['æ•°æ®æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
                # æŒ‰æ—¥æœŸåˆ†ç»„ï¼Œæ¯ä¸ªæ—¥æœŸä¿ç•™æœ€ä½³åŒ¹é…çš„è®°å½•
                trend_data_dict = {}
                for date, group in trend_data.groupby('æ•°æ®æ—¥æœŸ'):
                    # ä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼Œå…¶æ¬¡æ˜¯åŒ…å«åŒ¹é…
                    exact_match = group[group['åç§°'].str.upper() == sector_name_upper]
                    if not exact_match.empty:
                        trend_data_dict[date] = exact_match.iloc[0]
                    else:
                        trend_data_dict[date] = group.iloc[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…
                
                st.write(f"æ¿å—è¶‹åŠ¿æ•°æ®è·å–: æˆåŠŸï¼Œæ‰¾åˆ° {len(trend_data_dict)} ä¸ªæ—¥æœŸçš„æ•°æ®")
            else:
                st.warning(f"æœªæ‰¾åˆ°ä¸ '{sector_name}' åŒ¹é…çš„æ¿å—è¶‹åŠ¿æ•°æ®")
                # æ·»åŠ ä¸€ä¸ªåç§°_cirçš„ç©ºå€¼ï¼Œç¡®ä¿åç»­å¤„ç†æ—¶ä¸ä¼šå‡ºé”™
                st.write("åˆ›å»ºç©ºçš„æ¿å—è¶‹åŠ¿æ•°æ®å­—å…¸")
                trend_data_dict = {}
        except Exception as trend_error:
            error_message = str(trend_error).lower()
            
            if "timeout" in error_message or "connection" in error_message:
                st.warning(f"ğŸ“¶ æ¿å—è¶‹åŠ¿æ•°æ®æŸ¥è¯¢è¶…æ—¶æˆ–ç½‘ç»œé—®é¢˜: {str(trend_error)}")
                st.info("å°†ç»§ç»­å¤„ç†ï¼Œä½†å¯èƒ½ç¼ºå°‘æ¿å—è¶‹åŠ¿æ•°æ®")
            elif "table" in error_message and ("not exist" in error_message or "doesn't exist" in error_message):
                st.warning(f"ğŸ“‹ æ¿å—è¶‹åŠ¿æ•°æ®è¡¨ä¸å­˜åœ¨: {str(trend_error)}")
                st.info("å°†ç»§ç»­å¤„ç†ï¼Œä½†æ²¡æœ‰æ¿å—è¶‹åŠ¿æ•°æ®")
            else:
                st.warning(f"âš ï¸ æŸ¥è¯¢æ¿å—è¶‹åŠ¿æ•°æ®æ—¶å‡ºé”™: {str(trend_error)}")
            
            # è®°å½•è¯¦ç»†é”™è¯¯ï¼Œä½†ä¸ä¸­æ–­å¤„ç†
            with st.expander("æŸ¥çœ‹æ¿å—è¶‹åŠ¿æ•°æ®é”™è¯¯è¯¦æƒ…"):
                st.code(traceback.format_exc())
                
            trend_data_dict = {}
        
        # å‡†å¤‡æ‰¹é‡æ’å…¥æ•°æ®
        progress_text.write("æ­¥éª¤6/7: å‡†å¤‡æ‰¹é‡æ’å…¥æ•°æ®...")
        progress_bar.progress(70, text="å‡†å¤‡æ’å…¥æ•°æ®")
        
        # éå†æ¯ä¸ªéœ€è¦å¤„ç†çš„æ—¥æœŸ
        records_to_insert = []
        
        for date_str in dates_to_process:
            # è·å–è¯¥æ—¥æœŸçš„èµ„é‡‘æµå‘æ•°æ®
            cf_rows = capital_flow_data[pd.to_datetime(capital_flow_data['æ•°æ®æ—¥æœŸ']).dt.strftime('%Y-%m-%d') == date_str]
            
            if cf_rows.empty:
                st.warning(f"æ—¥æœŸ {date_str} æ²¡æœ‰èµ„é‡‘æµå‘æ•°æ®ï¼Œè·³è¿‡")
                continue
                
            cf_row = cf_rows.iloc[0]
            
            # åˆ›å»ºåŸºç¡€è®°å½•
            insert_data = {
                'ä»£ç ': sector_code,
                'åç§°': sector_name,
                'æ•°æ®æ—¥æœŸ': date_str
            }
            
            # æ·»åŠ èµ„é‡‘æµå‘æ•°æ®
            for col in cf_row.index:
                if col not in ['ä»£ç ', 'åç§°', 'æ•°æ®æ—¥æœŸ', 'åº']:
                    insert_data[col] = safe_get_value(cf_row, col)
            
            # æ·»åŠ DDEåˆ†ææ•°æ®
            if date_str in dde_data_dict:
                dde_row = dde_data_dict[date_str]
                for col in dde_row.index:
                    if col not in ['ä»£ç ', 'åç§°', 'æ•°æ®æ—¥æœŸ', 'åº', 'æœ€æ–°', 'æ¶¨å¹…%'] and col not in insert_data:
                        insert_data[col] = safe_get_value(dde_row, col)
            
            # æ·»åŠ æŒä»“åˆ†ææ•°æ®
            if date_str in position_data_dict:
                position_row = position_data_dict[date_str]
                for col in position_row.index:
                    if col not in ['ä»£ç ', 'åç§°', 'æ•°æ®æ—¥æœŸ', 'åº', 'æœ€æ–°', 'æ¶¨å¹…%'] and col not in insert_data:
                        insert_data[col] = safe_get_value(position_row, col)
            
            # æ·»åŠ æ¿å—è¶‹åŠ¿æ•°æ®
            if date_str in trend_data_dict:
                trend_row = trend_data_dict[date_str]
                
                # è°ƒè¯•è¾“å‡ºï¼ŒæŸ¥çœ‹æ¿å—è¶‹åŠ¿æ•°æ®çš„åŸå§‹åˆ—å
                if date_str == dates_to_process[0]:  # åªå¯¹ç¬¬ä¸€ä¸ªæ—¥æœŸè¿›è¡Œè¾“å‡ºä»¥å‡å°‘æ—¥å¿—
                    st.write(f"æ¿å—è¶‹åŠ¿æ•°æ®åŸå§‹å­—æ®µ: {list(trend_row.index)}")
                
                # ç‰¹æ®Šå¤„ç†æ¶¨å¹…å­—æ®µ - éœ€è¦æ·»åŠ "_st"åç¼€ä»¥åŒºåˆ†æ¥æº
                if "æ¶¨å¹…%" in trend_row.index:
                    insert_data["æ¶¨å¹…%_st"] = safe_get_value(trend_row, "æ¶¨å¹…%")
                
                if "3æ—¥æ¶¨å¹…%" in trend_row.index:
                    insert_data["3æ—¥æ¶¨å¹…%_st"] = safe_get_value(trend_row, "3æ—¥æ¶¨å¹…%")
                
                # å¤„ç†å…¶ä»–å­—æ®µ
                for col in trend_row.index:
                    # è·³è¿‡å·²ç»ç‰¹æ®Šå¤„ç†çš„å­—æ®µ
                    if col in ["æ¶¨å¹…%", "3æ—¥æ¶¨å¹…%", "ä»£ç ", "åç§°", "æ•°æ®æ—¥æœŸ", "åº"]:
                        continue
                    
                    # å¯¹æ‰€æœ‰å…¶ä»–å­—æ®µï¼Œå¦‚æœæ’å…¥æ•°æ®ä¸­ä¸å­˜åœ¨åˆ™æ·»åŠ 
                    if col not in insert_data:
                        insert_data[col] = safe_get_value(trend_row, col)
                
                # ç¡®ä¿å­˜å‚¨åŸå§‹æ¿å—åç§°
                if 'åç§°_cir' not in insert_data and 'åç§°' in trend_row.index:
                    insert_data['åç§°_cir'] = safe_get_value(trend_row, 'åç§°')
            
            # å°†NumPyç±»å‹è½¬æ¢ä¸ºæ ‡å‡†Pythonç±»å‹
            converted_data = {}
            for key, value in insert_data.items():
                converted_data[key] = convert_numpy_types(value)
            
            records_to_insert.append(converted_data)
        
        if not records_to_insert:
            progress_text.write("æ·»åŠ æ¿å—å®Œæˆ: æ²¡æœ‰æ–°çš„æœ‰æ•ˆæ•°æ®éœ€è¦æ·»åŠ ")
            progress_bar.progress(100, text="æ— æ•°æ®æ·»åŠ ")
            st.warning(f"æ¿å— {sector_code} {sector_name} æ²¡æœ‰æ–°çš„æœ‰æ•ˆæ•°æ®å¯æ·»åŠ ")
            return
        
        st.write(f"å‡†å¤‡æ’å…¥ {len(records_to_insert)} æ¡è®°å½•")
        
        # é¢„è§ˆéƒ¨åˆ†æ•°æ®
        preview_count = min(3, len(records_to_insert))
        st.write(f"æ•°æ®é¢„è§ˆ (å‰ {preview_count} æ¡):")
        preview_df = pd.DataFrame(records_to_insert[:preview_count])
        st.write(preview_df)
        
        # æ‰§è¡Œæ‰¹é‡æ’å…¥
        progress_text.write(f"æ­¥éª¤7/7: æ‰§è¡Œæ•°æ®æ’å…¥ ({len(records_to_insert)} æ¡è®°å½•)...")
        progress_bar.progress(90, text="æ’å…¥æ•°æ®")
        
        success_count = 0
        error_count = 0
        error_details = []
        
        for i, record in enumerate(records_to_insert):
            try:
                # è¿‡æ»¤æ‰å€¼ä¸ºNoneçš„é”®å€¼å¯¹
                filtered_record = {k: v for k, v in record.items() if v is not None}
                
                if len(filtered_record) < 3:  # è‡³å°‘éœ€è¦ä»£ç ã€åç§°å’Œæ—¥æœŸå­—æ®µ
                    raise ValueError("æœ‰æ•ˆå­—æ®µå¤ªå°‘ï¼Œæ— æ³•æ’å…¥")
                
                columns = list(filtered_record.keys())
                values = list(filtered_record.values())
                
                # æ£€æŸ¥å¹¶è®°å½•å€¼çš„æƒ…å†µ
                if i == 0 or i == len(records_to_insert) - 1:  # ä»…è®°å½•ç¬¬ä¸€æ¡å’Œæœ€åä¸€æ¡ä»¥å‡å°‘æ—¥å¿—é‡
                    st.write(f"è®°å½• #{i+1} ({filtered_record.get('æ•°æ®æ—¥æœŸ', 'N/A')}) å­—æ®µæ•°: {len(filtered_record)}")
                
                placeholders = ", ".join(["%s"] * len(columns))
                column_names = ", ".join([f"`{col}`" for col in columns])
                
                insert_query = f"""
                    INSERT INTO merged_data_specified ({column_names})
                    VALUES ({placeholders})
                """
                
                db.execute_update(insert_query, values)
                success_count += 1
                
                # æ›´æ–°è¿›åº¦
                current_progress = 90 + (i / len(records_to_insert)) * 10
                progress_bar.progress(min(int(current_progress), 99), text=f"å·²æ’å…¥ {i+1}/{len(records_to_insert)}")
                
            except Exception as insert_error:
                error_count += 1
                error_msg = f"æ’å…¥æ—¥æœŸ {record.get('æ•°æ®æ—¥æœŸ', 'æœªçŸ¥')} çš„æ•°æ®æ—¶å‡ºé”™: {str(insert_error)}"
                st.error(error_msg)
                error_details.append(error_msg)
                # ç»§ç»­å¤„ç†å…¶ä»–è®°å½•è€Œä¸æ˜¯ä¸­æ–­
        
        # å®Œæˆ
        progress_text.write(f"æ¿å—æ·»åŠ å®Œæˆ! æˆåŠŸ: {success_count}, å¤±è´¥: {error_count}")
        progress_bar.progress(100, text="æ“ä½œå®Œæˆ")
        
        if success_count > 0:
            st.success(f"æˆåŠŸæ·»åŠ æ¿å— {sector_code} {sector_name} çš„ {success_count} æ¡å†å²æ•°æ®åˆ°è·Ÿè¸ªæ± ")
        
        if error_count > 0:
            with st.expander(f"æŸ¥çœ‹ {error_count} æ¡å¤±è´¥è®°å½•çš„è¯¦æƒ…"):
                for i, error in enumerate(error_details):
                    st.write(f"{i+1}. {error}")
            st.warning(f"æœ‰ {error_count} æ¡è®°å½•æ’å…¥å¤±è´¥ï¼Œç‚¹å‡»ä¸Šæ–¹æŸ¥çœ‹è¯¦æƒ…")
            
    except Exception as e:
        progress_text.write("æ·»åŠ æ¿å—å¤±è´¥: å‘ç”ŸæœªçŸ¥é”™è¯¯")
        progress_bar.progress(100, text="æ“ä½œå¤±è´¥")
        
        error_message = str(e).lower()
        if "timeout" in error_message or "connection" in error_message:
            st.error(f"ğŸ“¶ æ•°æ®åº“è¿æ¥è¶…æ—¶æˆ–ç½‘ç»œé—®é¢˜: {str(e)}")
            st.info("ğŸ’¡ å»ºè®®: è¯·ç­‰å¾…å‡ ç§’é’Ÿåå†æ¬¡å°è¯•æ·»åŠ ")
        elif "duplicate" in error_message or "already exists" in error_message:
            st.error(f"ğŸ“‹ æ•°æ®é‡å¤: {str(e)}")
            st.info("ğŸ’¡ å»ºè®®: éƒ¨åˆ†æ•°æ®å¯èƒ½å·²ç»å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å·²æ·»åŠ è¯¥æ¿å—")
        else:
            st.error(f"âŒ æ·»åŠ æ¿å—å¤±è´¥: {str(e)}")
        
        with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
            st.code(traceback.format_exc())

# ä»è·Ÿè¸ªæ± ä¸­åˆ é™¤æ¿å—
def delete_sector_from_pool(sector_code):
    try:
        st.write("æ­£åœ¨æ‰§è¡Œåˆ é™¤æ“ä½œ...")
        delete_query = f"""
            DELETE FROM merged_data_specified 
            WHERE ä»£ç  = '{sector_code}'
        """
        st.code(delete_query, language="sql")
        db.execute_update(delete_query)
        st.success(f"æˆåŠŸä»è·Ÿè¸ªæ± ä¸­åˆ é™¤æ¿å— {sector_code}")
    except Exception as e:
        st.error(f"åˆ é™¤æ¿å—å¤±è´¥: {str(e)}")
        st.write(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
        st.write(traceback.format_exc())

# ä¸»ç•Œé¢
st.header("æ¿å—ç®¡ç†")

# æ˜¾ç¤ºå½“å‰è·Ÿè¸ªçš„æ¿å—åˆ—è¡¨
st.subheader("å½“å‰è·Ÿè¸ªçš„æ¿å—")
tracked_sectors = get_tracked_sectors()
if not tracked_sectors.empty:
    st.dataframe(tracked_sectors)
else:
    st.info("å½“å‰æ²¡æœ‰è·Ÿè¸ªçš„æ¿å—")

# æ·»åŠ æ–°æ¿å—
st.subheader("æ·»åŠ æ–°æ¿å—")
col1, col2 = st.columns(2)
with col1:
    sector_code = st.text_input("æ¿å—ä»£ç ", placeholder="ä¾‹å¦‚: BK0732")
with col2:
    sector_name = st.text_input("æ¿å—åç§°", placeholder="ä¾‹å¦‚: è´µé‡‘å±")

add_button = st.button("æ·»åŠ æ¿å—")
if add_button:
    # éªŒè¯è¾“å…¥æ˜¯å¦æœ‰æ•ˆ
    is_valid = True
    if not sector_code or sector_code.strip() == "":
        st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„æ¿å—ä»£ç ï¼")
        is_valid = False
    if not sector_name or sector_name.strip() == "":
        st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„æ¿å—åç§°ï¼")
        is_valid = False
    
    if is_valid:
        st.write(f"å¼€å§‹æ·»åŠ æ¿å—: {sector_code} - {sector_name}")
        with st.spinner(f"æ­£åœ¨æ·»åŠ æ¿å— {sector_code} - {sector_name}..."):
            add_sector_to_pool(sector_code, sector_name)
        st.write("å¤„ç†å®Œæˆï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®åˆ·æ–°é¡µé¢")
        if st.button("åˆ·æ–°é¡µé¢"):
            st.rerun()
    else:
        st.warning("è¯·æ£€æŸ¥å¹¶ä¿®æ­£ä¸Šé¢çš„é”™è¯¯ï¼Œç„¶åé‡è¯•")

# åˆ é™¤æ¿å—
st.subheader("åˆ é™¤æ¿å—")
if not tracked_sectors.empty:
    sector_to_delete = st.selectbox(
        "é€‰æ‹©è¦åˆ é™¤çš„æ¿å—",
        options=tracked_sectors['stock_code'].tolist(),
        format_func=lambda x: f"{x} - {tracked_sectors[tracked_sectors['stock_code'] == x]['stock_name'].iloc[0]}"
    )
    
    if st.button("åˆ é™¤é€‰ä¸­æ¿å—"):
        with st.spinner(f"æ­£åœ¨åˆ é™¤æ¿å— {sector_to_delete}..."):
            delete_sector_from_pool(sector_to_delete)
        st.write("å¤„ç†å®Œæˆï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®åˆ·æ–°é¡µé¢")
        if st.button("åˆ·æ–°é¡µé¢", key="refresh_after_delete"):
            st.rerun()
else:
    st.info("æ²¡æœ‰å¯åˆ é™¤çš„æ¿å—") 

# æ·»åŠ å…¨å±€æ‚¬æµ®åŠ©æ‰‹
try:
    add_global_assistant()
except Exception as e:
    print(f"Error adding global assistant: {e}")
